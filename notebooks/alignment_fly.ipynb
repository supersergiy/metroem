{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from six import iteritems\n",
    "import shelve\n",
    "from scipy.ndimage.measurements import label\n",
    "import h5py\n",
    "import json\n",
    "import sys \n",
    "import operator \n",
    "from scipy import ndimage\n",
    "\n",
    "from pdb import set_trace as st\n",
    "import copy\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "from IPython.html.widgets import interact, fixed\n",
    "from IPython.html import widgets\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from os.path import expanduser\n",
    "import time\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.nn.parallel import data_parallel\n",
    "from torchvision import transforms\n",
    "\n",
    "import random\n",
    "import six\n",
    "\n",
    "import importlib\n",
    "\n",
    "import artificery\n",
    "import metroem\n",
    "importlib.reload(metroem)\n",
    "import torchfields\n",
    "\n",
    "from metroem import loss\n",
    "from metroem import masks\n",
    "from metroem import alignment\n",
    "from metroem import aligner\n",
    "from metroem import train\n",
    "from metroem import helpers\n",
    "from metroem import dataset\n",
    "\n",
    "importlib.reload(helpers)\n",
    "importlib.reload(aligner)\n",
    "importlib.reload(alignment)\n",
    "importlib.reload(masks)\n",
    "importlib.reload(loss)\n",
    "importlib.reload(train)\n",
    "importlib.reload(dataset)\n",
    "\n",
    "from metroem.alignment import align_sample\n",
    "from metroem.loss import similarity_score, smoothness_penalty, get_dataset_loss, get_mse_and_smoothness_masks, smoothness_score\n",
    "from metroem.helpers import reverse_dim, downsample\n",
    "\n",
    "def visualize_residuals(res, figsize=(10,10), x_coords=None, y_coords=None, vec_grid=50):\n",
    "    res = prepare_for_show(res)\n",
    "    if res.shape[0] == 2:\n",
    "        res = np.transpose(res, (1, 2, 0))\n",
    "\n",
    "    assert res.shape[0] == res.shape[1]\n",
    "    plt.figure(figsize=figsize)\n",
    "    n = res.shape[0]\n",
    "    y, x = np.mgrid[0:n, 0:n]\n",
    "    \n",
    "    if x_coords is None:\n",
    "        x_coords = [0, res.shape[0]]\n",
    "    if y_coords is None:\n",
    "        y_coords = [0, res.shape[1]]\n",
    "    \n",
    "    ex = (1) * res[:, :, 0]\n",
    "    ey = res[:, :, 1]\n",
    "    r = np.arctan2(ex, ey)\n",
    "    \n",
    "    interval = (x_coords[1] - x_coords[0]) // vec_grid\n",
    "    \n",
    "    plt.quiver(  x[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval],  \n",
    "                 y[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval],\n",
    "                ex[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval], \n",
    "                ey[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval], \n",
    "                 r[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval], alpha=0.6)\n",
    "    plt.quiver(x[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval],  \n",
    "                 y[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval],\n",
    "                ex[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval], \n",
    "                ey[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval], edgecolor='k', facecolor='None', linewidth=.5)\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "def visualize_histogram(data, figsize=(10,10), x_coords=None, y_coords=None):\n",
    "    pass\n",
    "    \n",
    "def get_np(pt):\n",
    "    return pt.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def prepare_for_show(img):\n",
    "    if isinstance(img, torch.Tensor):\n",
    "         img = get_np(img)\n",
    "    img = img.squeeze()\n",
    "    return img\n",
    "\n",
    "\n",
    "rand_cmap = matplotlib.colors.ListedColormap(np.random.rand(256*32,3))\n",
    "\n",
    "def display_image(img, x_coords=None, y_coords=None, normalize=False, figsize=(10, 10), mask=False, segmentation=False):\n",
    "    if normalize and mask:\n",
    "        raise Exception(\"Masks can't be normalized\")\n",
    "    img = prepare_for_show(img)\n",
    "\n",
    "    if len(img.shape) == 3 and img.shape[-1] == 2:\n",
    "        visualize_residuals(img, x_coords=x_coords, y_coords=y_coords)\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    if x_coords is None:\n",
    "        x_coords = [0, img.shape[0]]\n",
    "    if y_coords is None:\n",
    "        y_coords = [0, img.shape[1]]\n",
    "    \n",
    "    if mask:\n",
    "        plt.imshow(img[x_coords[0]:x_coords[1], y_coords[0]:y_coords[1]], cmap='gray')\n",
    "    elif segmentation:\n",
    "        cmap='gray'\n",
    "        cmap = rand_cmap\n",
    "        \n",
    "        plt.imshow(img[x_coords[0]:x_coords[1], y_coords[0]:y_coords[1]].astype(np.int32), cmap=cmap)\n",
    "    elif not normalize:\n",
    "        plt.imshow(img[x_coords[0]:x_coords[1], y_coords[0]:y_coords[1]], cmap='gray', vmin=-1.5, vmax=1.5)\n",
    "    else:\n",
    "        plt.imshow(img[x_coords[0]:x_coords[1], y_coords[0]:y_coords[1]], cmap='gray')\n",
    "\n",
    "        \n",
    "def precompute_state(self, img_id, sup, val, state_file):\n",
    "    self.compute_state(img_id, sup, val)\n",
    "    try:\n",
    "        \n",
    "        state_h5 = h5py.File(state_file, 'w')\n",
    "        img_shape = self.src.shape\n",
    "        dset_shape = [0, 100, img_shape[3], img_shape[4]]\n",
    "        if \"main\" not in state_h5:\n",
    "            src_h5 = state_h5.create_dataset(\"main/src\", dset_shape)\n",
    "            tgt_h5 = state_h5.create_dataset(\"main/tgt\", dset_shape)\n",
    "            pred_tgt_h5 = state_h5.create_dataset(\"main/pred_tgt_h5\", dset_shape)\n",
    "        else:\n",
    "            src_h5 = state_h5[\"main/src\"]\n",
    "            tgt_h5 = state_h5[\"main/tgt\"]\n",
    "            pred_tgt_h5 = state_h5[\"main/pred_tgt\"]\n",
    "        src_h5[:, img_id:img_id+1, :, :] = 0#self.src \n",
    "        tgt_h5[:, img_id:img_id+1, :, :] = 0#self.tgt\n",
    "        pred_tgt_h5[:, img_id:img_id+1, :, :] = 0#self.pred_tgt_h5\n",
    "        state_h5.close()\n",
    "    except Exception as e:\n",
    "        state_h5.close()\n",
    "        raise e\n",
    "\n",
    "def filter_folds(viz_mse_mask_var, input_mip=6):\n",
    "    downsampler = nn.AvgPool2d(2) \n",
    "    for i in range(input_mip, 8):\n",
    "        viz_mse_mask_var = downsampler(viz_mse_mask_var)\n",
    "        \n",
    "    viz_mse_mask_var = (viz_mse_mask_var < 0.3).type(torch.cuda.DoubleTensor)\n",
    "                           \n",
    "    viz_mse_mask_var = viz_mse_mask_var.type(torch.cuda.ByteTensor)\n",
    "    mse_mask_np = get_np(viz_mse_mask_var.squeeze())\n",
    "    filtered_mse_mask_np = filter_connected_component(mse_mask_np, 100) == 0\n",
    "    return filtered_mse_mask_np\n",
    "\n",
    "        \n",
    "def segment_folds(fold_mask_np, memory_limit=None):\n",
    "    initial_segments = get_initial_segments(fold_mask_np, memory_limit)\n",
    "    segments  = cleanup_segment_stripes(initial_segments, n=16)\n",
    "    return segments\n",
    "\n",
    "def cleanup_segment_stripes(segments, n):\n",
    "    seg_t = np.copy(segments.T)\n",
    "    seg_start = np.zeros_like(seg_t[0])\n",
    "    last_seg = np.zeros_like(seg_t[1])\n",
    "    last_cleanup = 0\n",
    "    \n",
    "    for i in range(1, seg_t.shape[0]): \n",
    "        is_fold = seg_t[i] == 0\n",
    "        was_fold = seg_t[i - 1] == 0\n",
    "        last_seg_fold = last_seg == 0\n",
    "        \n",
    "        new_seg = (seg_t[i] != seg_t[i - 1])\n",
    "        seg_width = i - seg_start\n",
    "        \n",
    "        bad_seg = new_seg * (seg_width < n) * (was_fold == False) * (is_fold == False)\n",
    "        bad_seg_names = np.unique(seg_t[i - 1][bad_seg])\n",
    "        \n",
    "        if len(bad_seg_names) > 0:\n",
    "            print (i, last_cleanup, bad_seg_names)\n",
    "            cleanup_seg_id = i - 2\n",
    "            ref_seg_id = i - 1\n",
    "\n",
    "            ids_to_clean = None\n",
    "            change_to_these = np.maximum(last_seg, new_seg)\n",
    "            while (cleanup_seg_id >= 0):\n",
    "                ids_to_clean = (seg_t[cleanup_seg_id] == seg_t[ref_seg_id]) * bad_seg * (last_seg_fold == False)\n",
    "                if np.any(ids_to_clean) == False:\n",
    "                    break\n",
    "                seg_t[cleanup_seg_id][ids_to_clean] = change_to_these[ids_to_clean]\n",
    "                cleanup_seg_id -= 1\n",
    "            seg_t[ref_seg_id][bad_seg * (last_seg_fold == False)] = change_to_these[bad_seg * (last_seg_fold == False)]\n",
    "            last_cleanup = i\n",
    "                                  \n",
    "        last_seg[new_seg] = seg_t[i - 1][new_seg]\n",
    "        seg_start[new_seg] = i\n",
    "    return seg_t.T\n",
    "\n",
    "def get_initial_segments(fold_mask_np, memory_limit, smallest_seg):\n",
    "    folds = fold_mask_np == False\n",
    "    segments = np.zeros_like(folds, dtype=np.int32)\n",
    "    last_fold = np.zeros_like(folds[0], dtype=np.int32)\n",
    "    seg_start = np.zeros_like(folds[0], dtype=np.int32)\n",
    "    \n",
    "    segments[0] = 1\n",
    "    segments[0][folds[0]] = 0\n",
    "    max_in_line = np.copy(segments[0])\n",
    "    \n",
    "    \n",
    "    for i in range(1, folds.shape[0]):\n",
    "        \n",
    "        \n",
    "        is_fold = folds[i]\n",
    "        was_fold = folds[i - 1]\n",
    "        curr_seg = segments[i]\n",
    "        last_seg = segments[i - 1]\n",
    "        \n",
    "        continue_ids = (is_fold == False) * (was_fold == False)\n",
    "        short_stretch = (i - seg_start) < smallest_seg\n",
    "        \n",
    "        new_seg_ids = (is_fold == False) * (was_fold == True) * (short_stretch == False)\n",
    "        jump_seg_ids = (is_fold == False) * (was_fold == True) * (short_stretch == True)\n",
    "        \n",
    "        curr_seg[continue_ids] = last_seg[continue_ids]\n",
    "        curr_seg[new_seg_ids] = (max_in_line + 1)[new_seg_ids]\n",
    "        \n",
    "        fresh_start_ids = max_in_line == 0\n",
    "        curr_seg[jump_seg_ids * (fresh_start_ids == False)] = max_in_line[jump_seg_ids * (fresh_start_ids == False)]\n",
    "        curr_seg[jump_seg_ids * (fresh_start_ids == True)] = (max_in_line + 1)[jump_seg_ids * (fresh_start_ids == True)]\n",
    "        \n",
    "        seg_start[new_seg_ids] = i\n",
    "        \n",
    "        curr_seg[is_fold == True] = 0\n",
    "        max_in_line = np.maximum(max_in_line, curr_seg)\n",
    "        \n",
    "        '''if memory_limit is not None:\n",
    "            forgotten_folds = (i - last_fold) > memory_limit\n",
    "            max_in_line[forgotten_folds] = np.maximum(1, max_in_line[forgotten_folds] - 1)'''\n",
    "        last_fold[is_fold] = i\n",
    "        \n",
    "    return segments \n",
    "\n",
    "def expand_mask(mask_np, n=33):\n",
    "    mask_var = torch.FloatTensor(mask_np.astype(np.float)).unsqueeze(0).unsqueeze(0)\n",
    "    kernel = torch.ones([1, 1, n, n])\n",
    "    expanded_mask = torch.nn.functional.conv2d(mask_var, kernel, padding=n//2) \n",
    "    expanded_mask_np = get_np(expanded_mask[0, 0]) > 0\n",
    "    return expanded_mask_np\n",
    "\n",
    "class PyramidVisualizer(object):\n",
    "    def __init__(self, pyramid, def_sup=False):\n",
    "        self.reverse = True\n",
    "        self.fold_size = None\n",
    "        self.src = None\n",
    "        self.prev_id = -1\n",
    "        self.prev_is_val = False\n",
    "        self.prev_is_sup = False\n",
    "        self.val_dataset = None\n",
    "        self.train_dataset = None\n",
    "        self.def_sup = True\n",
    "        self.def_norm_img = False\n",
    "        self.viz_mip = 0\n",
    "        self.run_mip = 0\n",
    "        self.sup = False\n",
    "        self.prerun_augment = []\n",
    "        \n",
    "        self.pyramid = pyramid\n",
    "        self.run_mip = 0\n",
    "        self.viz_mip = 0\n",
    "        \n",
    "        \n",
    "        self.dataset_mip, self.sup_train_dataset = get_datasets()\n",
    "        #self.upsampler = nn.UpsamplingBilinear2d(scale_factor=2)   \n",
    "        self.mse_keys_to_apply = {\n",
    "        'src': [\n",
    "            {'name': 'src_defects',\n",
    "             'binarization': {'strat': 'eq', 'value': 0},\n",
    "             \"not_coarsen_ranges\": [ (0,25)] },\n",
    "            {'name': 'src',\n",
    "             \"not_coarsen_ranges\": [(1, 0)],\n",
    "             'binarization': {'strat': 'neq', 'value': 0}\n",
    "             }\n",
    "            ],\n",
    "        'tgt':[\n",
    "            {'name': 'tgt_defects',\n",
    "             'binarization': {'strat': 'eq', 'value': 0},\n",
    "             \"coarsen_ranges\": [(0, 0)]},\n",
    "            {'name': 'tgt',\n",
    "             \"not_coarsen_ranges\": [(10, 0)],\n",
    "             'binarization': {'strat': 'neq', 'value': 0}\n",
    "             }\n",
    "        ]\n",
    "    }\n",
    "        self.sm_keys_to_apply = {                                                                                                 \n",
    "           \"src\": [                                                                                                          \n",
    "               {\"name\": \"src_defects\",                                                                                      \n",
    "                \"binarization\": {\"strat\": \"eq\", \"value\": 0},                                                               \n",
    "                \"not_coarsen_ranges\": [[1, 0.2], [4, 5.0]],                                                             \n",
    "                \"mask_value\": 1.0e-5},                                                                                       \n",
    "             {\"name\": \"src\",                                                                                             \n",
    "                \"fm\": 0,                                                                                                  \n",
    "                \"binarization\": {\"strat\": \"neq\", \"value\": 0}}                                                            \n",
    "           ],                                                                                                              \n",
    "           \"tgt\":[                                                                                                        \n",
    "               {\"name\": \"tgt_defects\",                                                                                   \n",
    "                \"binarization\": {\"strat\": \"eq\", \"value\": 0},                                                                 \n",
    "                #\"not_coarsen_ranges\": [[1, 0.2], [2, 0.4], [3, 0.6], [4, 0.8]],                                                              \n",
    "                \"mask_value\": 0.0e-5}                                                                                         \n",
    "           ]                                                                                                              \n",
    "       }\n",
    "        \n",
    "    \n",
    "        \n",
    "    def set_model(self, model):\n",
    "        self.pyramid = model\n",
    "        self.prev_id = -1\n",
    "    \n",
    "    def update_state(self, img_id, sup, val, state_file):\n",
    "        if state_file is None:\n",
    "            \n",
    "            self.compute_state(img_id, sup, val)\n",
    "        else:\n",
    "            self.load_state(img_id, sup, val, state_file)\n",
    "            \n",
    "    def compute_state(self, img_id, sup, val):\n",
    "        self.dataset = self.sup_train_dataset\n",
    "                \n",
    "        if self.prev_id == -1:\n",
    "            self.clean_up()\n",
    "            \n",
    "        #make it refresh when sup is changed\n",
    "        if self.prev_id == -1 or self.prev_is_sup != sup:\n",
    "            self.prev_is_sup = sup\n",
    "            self.prev_id = -1\n",
    "            \n",
    "\n",
    "        if img_id != self.prev_id or self.prev_is_val != val:\n",
    "            self.prev_id = img_id\n",
    "            self.prev_is_val = val\n",
    "            #clean_sample = self.dataset[img_id][:, 2:-30, 2:-30].unsqueeze(0)\n",
    "            \n",
    "            raw_sample = copy.deepcopy(self.dataset[img_id])\n",
    "           \n",
    "            for aug in self.prerun_augment:\n",
    "                if aug['type'] == 'contrast_half_src':\n",
    "                    src = raw_sample[0, 0]\n",
    "                    src[src.shape[0]//2:, :] *= aug['mult']\n",
    "                elif aug['type'] == 'brightness_half_src':\n",
    "                    src = raw_sample[0, 0]\n",
    "                    src[src.shape[0]//2:, :] += aug['bump']\n",
    "                else:\n",
    "                    raise Exception(\"Unknown prerun transofm\")\n",
    "                    \n",
    "            for k, v in six.iteritems(raw_sample):\n",
    "                #print (v.shape)\n",
    "                # why are we doing this\n",
    "                raw_sample[k] = v.unsqueeze(0)  \n",
    "                \n",
    "            run_sample = copy.deepcopy(raw_sample)\n",
    "            self.run_sample = run_sample\n",
    "            for k, v in six.iteritems(run_sample):\n",
    "                #print (v.shape)\n",
    "                # why are we doing this: to have the same orientation as ng\n",
    "                #run_sample[k] = v.permute(0, 2, 1)\n",
    "                pass\n",
    "            \n",
    "            model_run_params = {\"level_in\": self.run_mip}\n",
    "            \n",
    "            run_result = align_sample(self.pyramid, run_sample)\n",
    "            for k, v in six.iteritems(run_result):\n",
    "                if hasattr(v, 'detach'):\n",
    "                    run_result[k] = v.detach()\n",
    "                \n",
    "            run_src_var = run_result['src'].unsqueeze(0)                                                                   \n",
    "            run_tgt_var = run_result['tgt'].unsqueeze(0)                                                                                                                             \n",
    "            run_pred_res_var = run_result['pred_res']                                                                \n",
    "            del run_result\n",
    "            \n",
    "            '''run_result = self.pyramid.run_pair(run_sample.unsqueeze(0), self.run_mip, reverse=self.reverse)\n",
    "            run_src_var, run_tgt_var, run_true_res_var, run_pred_res_var, run_pred_tgt_var, run_masks_var = run_result\n",
    "            \n",
    "            del run_result, run_true_res_var, run_pred_tgt_var, run_masks_var'''\n",
    "            \n",
    "            #clean_smale = self.dataset[img_id][:, 2:-30, 2:-30].unsqueeze(0)\n",
    "            viz_sample = copy.deepcopy(raw_sample)\n",
    "                    \n",
    "            viz_src_var = viz_sample['src']\n",
    "            viz_tgt_var = viz_sample['tgt']\n",
    "            \n",
    "            if self.sup:\n",
    "                viz_true_res_var = viz_sample['res']\n",
    "\n",
    "            viz_src_var = viz_src_var\n",
    "            viz_tgt_var = viz_tgt_var\n",
    "            \n",
    "            \n",
    "            viz_pred_res_var = run_pred_res_var#.permute(0, 2, 1, 3).flip(3)\n",
    "            \n",
    "            viz_pred_res_var = viz_pred_res_var.squeeze()\n",
    "            viz_sample['pred_res'] = viz_pred_res_var\n",
    "            \n",
    "            if 'src_field' in viz_sample:\n",
    "                src_res_var = viz_sample['src_field'].field()\n",
    "            else:\n",
    "                src_res_var = torch.zeros_like(run_pred_res_var).field()\n",
    "                \n",
    "            viz_warped_src_var = src_res_var.from_pixels()(viz_src_var)\n",
    "            viz_pred_tgt_var = viz_pred_res_var.from_pixels()(viz_src_var)\n",
    "            \n",
    "            viz_sample['pred_tgt'] = viz_pred_tgt_var\n",
    "\n",
    "\n",
    "            viz_mse_mask_var, viz_smoothness_mask_var = get_mse_and_smoothness_masks(viz_sample, \n",
    "                                                                                     mse_keys_to_apply=self.mse_keys_to_apply,\n",
    "                                                                                    sm_keys_to_apply=self.sm_keys_to_apply)\n",
    "            \n",
    "            \n",
    "            self.viz_sample = viz_sample\n",
    "            # Todo: visualize different penalties\n",
    "            \n",
    "            viz_rigidity_penalty_var = loss.rigidity(viz_pred_res_var.unsqueeze(0))\n",
    "            viz_smoothness_penalty_var = viz_rigidity_penalty_var\n",
    "            \n",
    "            norm_tgt_var = torch.nn.InstanceNorm2d(1)(viz_tgt_var.unsqueeze(0))\n",
    "            norm_pred_tgt_var = torch.nn.InstanceNorm2d(1)(viz_pred_tgt_var.unsqueeze(0))\n",
    "            viz_masked_nrom_diff_var = viz_mse_mask_var * torch.abs(viz_tgt_var - viz_pred_tgt_var)\n",
    "            del norm_tgt_var, norm_pred_tgt_var\n",
    "            \n",
    "            viz_diff_var = (viz_tgt_var - viz_pred_tgt_var)**2\n",
    "            viz_masked_diff_var = viz_diff_var * viz_mse_mask_var\n",
    "            viz_inv_res = torch.zeros_like(viz_pred_res_var)\n",
    "            combined_identity_var = viz_inv_res\n",
    " \n",
    "            self.img_dict = {\n",
    "                'Source': {\"img\": get_np(viz_src_var), \"norm\": self.def_norm_img},\n",
    "                'Warped Source': {\"img\": get_np(viz_warped_src_var), \"norm\": self.def_norm_img},\n",
    "                'Target': {\"img\": get_np(viz_tgt_var), \"norm\": self.def_norm_img},\n",
    "                'Predicted Target': {\"img\": get_np(viz_pred_tgt_var), \"norm\": self.def_norm_img},\n",
    "                'Diff': {\"img\": get_np(viz_diff_var), \"norm\": self.def_norm_img},\n",
    "                'Masked Diff': {\"img\": get_np(viz_masked_diff_var),\n",
    "                                \"norm\": self.def_norm_img},\n",
    "                'MSE Mask': {\"img\": get_np(viz_mse_mask_var)},\n",
    "                'Masked Norm Diff': {\"img\": get_np(viz_masked_nrom_diff_var), \"norm\": self.def_norm_img},\n",
    "                'Smoothness': {\"img\": get_np(viz_smoothness_penalty_var), \"norm\": self.def_norm_img},\n",
    "                'Rigidity': {\"img\": get_np(viz_rigidity_penalty_var), \"norm\": self.def_norm_img},\n",
    "                'Smoothness Mask': {\"img\": get_np(viz_smoothness_mask_var)},\n",
    "                'Masked Smoothness': {\"img\": get_np(viz_smoothness_mask_var * viz_smoothness_penalty_var), \n",
    "                                      \"norm\": self.def_norm_img},\n",
    "                'Masked Rigidity': {\"img\": get_np(viz_smoothness_mask_var * viz_rigidity_penalty_var), \n",
    "                                      \"norm\": self.def_norm_img},\n",
    "            }\n",
    "\n",
    "            self.vect_dict = {\n",
    "                'Predicted Residual': get_np(viz_pred_res_var),\n",
    "                'Source Residual': get_np(src_res_var),\n",
    "                'Inverted Residual': get_np(viz_inv_res),\n",
    "                'Combined': get_np(combined_identity_var)\n",
    "            }\n",
    "            \n",
    "            self.hist_dict = {\n",
    "                'Residual Histogram': get_np(viz_pred_res_var),\n",
    "            }\n",
    "            \n",
    "            if self.sup:\n",
    "                self.vect_dict['True Residual'] = get_np(viz_true_res_var),\n",
    "                self.vect_dict['Residual Error'] =  get_np(viz_true_res_var - viz_pred_res_var)\n",
    "    \n",
    "    def clean_up(self):\n",
    "        self.img_dict = {}\n",
    "        self.vect_dict = {}\n",
    "       \n",
    "    def loadimg(self, val, sup, section_count, img_id, x_section, y_section, choice, state_file):\n",
    "        self.update_state(img_id, sup, val, state_file)\n",
    "        \n",
    "        if choice in self.img_dict:\n",
    "            normalize = ('norm' in self.img_dict[choice]) and (self.img_dict[choice]['norm'])\n",
    "            is_mask = ('Mask ' in choice) or (' Mask' in choice)\n",
    "            is_seg = ('segment' in choice.lower())\n",
    "            img = copy.copy(prepare_for_show(self.img_dict[choice]['img']))\n",
    "            \n",
    "            x_section_size = img.shape[0] // section_count\n",
    "            y_section_size = img.shape[1] // section_count\n",
    "            \n",
    "            x_coords = (x_section_size * x_section, x_section_size * (x_section + 1))\n",
    "            y_coords = (y_section_size * y_section, y_section_size * (y_section + 1))\n",
    "\n",
    "            if choice in ['Diff',  'Masked Diff']:\n",
    "                print ('MSE: {}'.format(np.mean(np.abs(img[x_coords[0]:x_coords[1], y_coords[0]:y_coords[1]]))))\n",
    "            display_image(img, mask=is_mask, segmentation=is_seg, normalize=normalize, x_coords=x_coords, y_coords=y_coords)\n",
    "            \n",
    "        elif choice in self.vect_dict:\n",
    "            vecs = prepare_for_show(self.vect_dict[choice])\n",
    "\n",
    "            x_section_size = vecs.shape[1] // section_count\n",
    "            y_section_size = vecs.shape[2] // section_count\n",
    "            \n",
    "            x_coords = (x_section_size * x_section, x_section_size * (x_section + 1))\n",
    "            y_coords = (y_section_size * y_section, y_section_size * (y_section + 1))\n",
    "            \n",
    "            \n",
    "            visualize_residuals(vecs, x_coords=x_coords, y_coords=y_coords)\n",
    "\n",
    "        elif choice in self.hist_dict:\n",
    "            img = self.hist_dict[choice]\n",
    "            x_section_size = img.shape[0] // section_count\n",
    "            y_section_size = img.shape[1] // section_count\n",
    "            \n",
    "            x_coords = (x_section_size * x_section, x_section_size * (x_section + 1))\n",
    "            y_coords = (y_section_size * y_section, y_section_size * (y_section + 1))\n",
    "            visualize_histogram(img, x_coords=x_coords, y_coords=y_coords)\n",
    "       \n",
    "    def visualize(self, section_count=1, state_file=None, default_slice=9, default_x=0, default_y=0):\n",
    "        \n",
    "        self.id_selector = widgets.IntText(\n",
    "            value=default_slice,\n",
    "            description='Sample ID:',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        self.val_selector = widgets.Checkbox(\n",
    "            value=False,\n",
    "            description='Take from validation set',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.sup_selector = widgets.Checkbox(\n",
    "            value=self.def_sup,\n",
    "            description='Take from supervised dataset',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        self.section_count_selector = widgets.IntText(\n",
    "            value=section_count,\n",
    "            description='Section Count:',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        self.x_section_selector = widgets.IntText(\n",
    "            value=default_x,\n",
    "            description='X section:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.y_section_selector = widgets.IntText(\n",
    "            value=default_y,\n",
    "            description='Y section:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        buttons = ['Source', 'Warped Source', 'Target', 'Predicted Target', \n",
    "                   'Source Residual', 'Predicted Residual', 'Inverted Residual', \n",
    "                   'Combined',  'Diff', 'MSE Mask', 'Masked Diff', 'Residual Histogram',\n",
    "                   'Smoothness Mask', 'Smoothness', 'Rigidity', 'Masked Smoothness', 'Masked Rigidity']\n",
    "\n",
    "        # for supervised\n",
    "        #buttons += ['True Residual', 'Error histogram', 'Vector histogram', 'Residual Error'],\n",
    "        self.button_choice_1 = widgets.ToggleButtons(\n",
    "            options=buttons,\n",
    "            description='Choice:',\n",
    "            disabled=False,\n",
    "            button_style='',\n",
    "        #     icons=['check'] * 3\n",
    "        )\n",
    "        interact(self.loadimg, img_id=self.id_selector, val=self.val_selector, sup=self.sup_selector, \n",
    "                 section_count=self.section_count_selector, x_section=self.x_section_selector, y_section=self.y_section_selector, \n",
    "                 choice=self.button_choice_1, state_file=fixed(state_file))\n",
    "\n",
    "\n",
    "            \n",
    "class simple_visualizer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def display_multiimg(self, choice):\n",
    "        i = self.names.index(choice)\n",
    "        if isinstance(self.images[i], torch.Tensor):\n",
    "            self.images[i] = self.images[i].cpu().detach().numpy()\n",
    "        self.images[i].squeeze()\n",
    "        \n",
    "        plt.figure(figsize = (12,12))\n",
    "        if self.crop == 0:\n",
    "            plt.imshow(self.images[i], cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(self.images[i][self.crop:-self.crop, self.crop:-self.crop], cmap='gray')\n",
    "    \n",
    "    def loadimg(self, choice, section_count, x_section, y_section):\n",
    "        i = self.names.index(choice)\n",
    "        if isinstance(self.images[i], torch.Tensor):\n",
    "            self.images[i] = self.images[i].cpu().detach().numpy()\n",
    "        self.images[i].squeeze()\n",
    "        img = self.images[i].squeeze()\n",
    "        img = prepare_for_show(img)\n",
    "        x_section_size = img.shape[0] // section_count\n",
    "        y_section_size = img.shape[1] // section_count\n",
    "\n",
    "        x_coords = (x_section_size * x_section, x_section_size * (x_section + 1))\n",
    "        y_coords = (y_section_size * y_section, y_section_size * (y_section + 1))\n",
    "        \n",
    "        display_image(img, normalize=True, x_coords=x_coords, y_coords=y_coords)\n",
    "        \n",
    "    def visualize(self, images, names=None, crop=0, section_count=1, x_section=0, y_section=0):\n",
    "        if names is None:\n",
    "            names = range(len(images))\n",
    "        self.names = names\n",
    "        self.images = images\n",
    "        self.crop = crop\n",
    "        \n",
    "        button_choice = widgets.ToggleButtons(\n",
    "                options=names,\n",
    "                description='Image:',\n",
    "                disabled=False,\n",
    "                button_style='',\n",
    "            )\n",
    "        \n",
    "        self.section_count_selector = widgets.IntText(\n",
    "            value=section_count,\n",
    "            description='Section Count:',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        self.x_section_selector = widgets.IntText(\n",
    "            value=x_section,\n",
    "            description='X section:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.y_section_selector = widgets.IntText(\n",
    "            value=y_section,\n",
    "            description='Y section:',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        interact(self.loadimg, choice=button_choice, \n",
    "                 section_count=self.section_count_selector, \n",
    "                 x_section=self.x_section_selector, y_section=self.y_section_selector)\n",
    "\n",
    "\n",
    "def get_datasets():\n",
    "    dataset_mip = 7\n",
    "    stage = 0\n",
    "    checkpoint_name = 'mse_final'\n",
    "    \n",
    "    #big_data = dataset.MultimipDataset(\"/usr/people/popovych/metro_datasets/large_test_x1\", field_tag=checkpoint_name)\n",
    "    big_data = dataset.MultimipDataset(\"/usr/people/popovych/metro_datasets/fly_full_x4_bigtest\", field_tag=checkpoint_name)\n",
    "    train_dataset = big_data.get_train_dset(mip=dataset_mip, stage=stage, crop_mode='middle', cropped_size=2048)\n",
    "    return dataset_mip, train_dataset\n",
    "    \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "\n",
    "MAX_SEG_PER_CHUNK = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import artificery\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "def load_my_state_dict(model, state_dict):\n",
    "    own_state = model.state_dict()\n",
    "    for name, param in state_dict.items():\n",
    "        if name not in own_state:\n",
    "             continue\n",
    "        if isinstance(param, Parameter):\n",
    "            # backwards compatibility for serialized parameters\n",
    "            param = param.data\n",
    "        own_state[name].copy_(param)\n",
    "            \n",
    "def create_model(name, checkpoint_folder, checkpoint_init=False):                                                                                                                                                     \n",
    "    a = artificery.Artificery(checkpoint_init=checkpoint_init)    \n",
    "    \n",
    "    spec_path = os.path.join(checkpoint_folder, \"model_spec.json\")\n",
    "    my_p = a.parse(spec_path)                                                                                                                                                                \n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_folder, \"{}.state.pth.tar\".format(name))                                                                                                                     \n",
    "    if os.path.isfile(checkpoint_path):         \n",
    "        load_my_state_dict(my_p, torch.load(checkpoint_path))\n",
    "        #my_p.load_state_dict(torch.load(checkpoint_path))                                                                                                                                                  \n",
    "    my_p.name = name                                                                                                                                                                                       \n",
    "    return my_p.cuda()  \n",
    "\n",
    "def lap2(field):\n",
    "    def dxf(f):\n",
    "        p = Variable(torch.zeros((1,1,f.size(1),2))).cuda()\n",
    "        return torch.cat((p, f[:,1:-1,:,:] - f[:,2:,:,:], p), 1)\n",
    "    def dyf(f):\n",
    "        p = Variable(torch.zeros((1,f.size(1),1,2))).cuda()\n",
    "        return torch.cat((p, f[:,:,1:-1,:] - f[:,:,2:,:], p), 2)\n",
    "    result = [field_dx(field), field_dy(field), dxf(field), dyf(field)]\n",
    "    result = (sum(result) / 4.0) ** 2\n",
    "    result = sum(torch.sum(result, -1))\n",
    "    return result\n",
    "\n",
    "def field_dx(f, forward=False):\n",
    "    if forward:\n",
    "        delta = f[:,1:-1,:,:] - f[:,2:,:,:]\n",
    "    else:\n",
    "        delta = f[:,1:-1,:,:] - f[:,:-2,:,:]\n",
    "    result = delta\n",
    "    result = torch.nn.functional.pad(delta, pad=(0, 0, 0, 0, 1, 1, 0, 0))\n",
    "    return result\n",
    "\n",
    "def field_dy(f, forward=False):\n",
    "    if forward:\n",
    "        delta = f[:,:,1:-1,:] - f[:,:,2:,:]\n",
    "    else:\n",
    "        delta = f[:,:,1:-1,:] - f[:,:,:-2,:]\n",
    "    result = delta\n",
    "    result = torch.nn.functional.pad(delta, pad=(0, 0, 1, 1, 0, 0, 0, 0))\n",
    "    return result\n",
    "\n",
    "def field_dxy(f, forward=False):\n",
    "    if forward:\n",
    "        delta = f[:,1:-1,1:-1,:] - f[:,2:,2:,:]\n",
    "    else:\n",
    "        delta = f[:,1:-1,1:-1,:] - f[:,:-2,:-2,:]\n",
    "        \n",
    "    result = delta\n",
    "    result = torch.nn.functional.pad(delta, pad=(0, 0, 1, 1, 1, 1, 0, 0))\n",
    "    return result\n",
    "\n",
    "\n",
    "def pix_identity(size, batch=1, device='cuda'):\n",
    "    result = torch.zeros((batch, size, size, 2), device=device)\n",
    "    x = torch.arange(size, device=device)\n",
    "    result[:, :, :, 1] = x\n",
    "    result = torch.transpose(result, 1, 2)\n",
    "    result[:, :, :, 0] = x\n",
    "    result = torch.transpose(result, 1, 2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4032, 3024)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "# Open the image form working directory\n",
    "image = Image.open(os.path.expanduser('~/labpic.jpg'))\n",
    "# summarize some details about the image\n",
    "#print(image.format)\n",
    "print(image.size)\n",
    "#print(image.mode)\n",
    "# show the image\n",
    "img_grey = image.convert('L')\n",
    "#img_grey.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "img_grey = img_grey.crop((256, 0, 4032 - 512 - 240 , 3024))\n",
    "#img_grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/usr/people/popovych/.modelhouse/tmp_files/tmp04lu0lhu/model/model_spec.json\n",
      "block_6convs_fms8to32_skip25.json\n",
      "categorical/categorical_compch15_gridfalse_maxvalue7_outch2_stepnull_trainsttrue.json\n",
      "block_6convs_fms8to32_skip25.json\n",
      "categorical/categorical_compch15_gridfalse_maxvalue7_outch2_stepnull_trainsttrue.json\n",
      "identity.json\n",
      "embedder_m0_3x3_fms1x.json\n",
      "block_5convs_3x3_fms1to1_skip14.json\n",
      "average_pool.json\n",
      "embedder_fms2to3.json\n",
      "block_3convs_3x3_fms2to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "upsample_residuals.json\n",
      "identity.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/people/popovych/artificery/artificery/parsers/categorical_regression/parse.py:38: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  requires_grad=False) - self.component_channels//2\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import modelhouse\n",
    "import metroem\n",
    "\n",
    "from metroem import finetuner\n",
    "from metroem import masks\n",
    "importlib.reload(finetuner)\n",
    "importlib.reload(masks)\n",
    "from metroem.finetuner import optimize_pre_post_ups\n",
    "\n",
    "def opt(src, tgt, pred_res_start, src_defects=None, tgt_defects=None, lr=18e-1, sm=2e1):\n",
    "    mse_keys_to_apply = {\n",
    "\n",
    "    }\n",
    "    sm_keys_to_apply = {  \n",
    "        'src': [\n",
    "            {'name': 'src',\n",
    "             'fm': 0,\n",
    "             \"coarsen_ranges\": [ (0, 0)],\n",
    "             'binarization': {'strat': 'neq', 'value': -1},\n",
    "             }\n",
    "            ],\n",
    "        'tgt': [\n",
    "\n",
    "            ],\n",
    "                                                                                                        \n",
    "    }\n",
    "    \n",
    "    src_small_defects = None\n",
    "    src_large_defects = None\n",
    "    \n",
    "        \n",
    "    if src_small_defects is not None:\n",
    "        src_small_defects = src_small_defects.squeeze(0)\n",
    "    else:\n",
    "        src_small_defects = torch.zeros_like(src)\n",
    "        \n",
    "    if src_large_defects is not None:\n",
    "        src_large_defects = src_large_defects.squeeze(0)\n",
    "    else:\n",
    "        src_large_defects = torch.zeros((src.shape[-1], src.shape[-1]))\n",
    "\n",
    "    pred_res_opt = optimize_pre_post_ups(src, tgt, pred_res_start,\n",
    "            src_defects=torch.zeros_like(src_defects),\n",
    "            tgt_defects=torch.zeros_like(tgt_defects),\n",
    "            crop=4, num_iter=10000,\n",
    "            opt_res_coarsness=0,\n",
    "            sm_keys_to_apply=sm_keys_to_apply,\n",
    "            mse_keys_to_apply=mse_keys_to_apply,\n",
    "            normalize=False,\n",
    "            sm=sm, lr=lr)\n",
    "    \n",
    "    return pred_res_opt\n",
    "\n",
    "class OptiPrecoarse(torch.nn.Module):\n",
    "    def __init__(self, embedder_path='gs://corgie/models/fly_m11_embedder_x0', \n",
    "                 embedder_params={\n",
    "                    \"checkpoint_name\": \"checkpoint_x0\",\n",
    "                    \"finetune\": False\n",
    "                },\n",
    "                 device='cuda',\n",
    "                 level=-1,\n",
    "                 sm=2e1,\n",
    "                 mask_value=-1\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.embedder = modelhouse.load_model(embedder_path, params=json.dumps(embedder_params))\n",
    "        self.device = device\n",
    "        self.level = level\n",
    "        self.sm = sm\n",
    "        self.mask_value = mask_value\n",
    "        \n",
    "    def forward(self, src_img, tgt_img, src_agg_field=None):\n",
    "        self.embedder(src_img=src_img, tgt_img=tgt_img)\n",
    "        src_emb, tgt_emb = self.embedder.aligner.get_embeddings()\n",
    "        assert src_emb[self.level].shape[0] == 1\n",
    "        \n",
    "        \n",
    "        src_mask = src_emb[self.level][0, 0] == 0\n",
    "        src_mask = masks.coarsen_mask(src_mask.float(), flip=False).squeeze() != 0\n",
    "        src_emb = src_emb[self.level][0, 1:]\n",
    "        src_emb[:, src_mask] = self.mask_value\n",
    "        \n",
    "        \n",
    "        tgt_mask = tgt_emb[self.level][0, 0] == 0\n",
    "        tgt_mask = masks.coarsen_mask(tgt_mask.float(), flip=False).squeeze() != 0\n",
    "        tgt_emb = tgt_emb[self.level][0, 1:]\n",
    "        tgt_emb[:, tgt_mask] = self.mask_value\n",
    "        \n",
    "        if src_agg_field is None:\n",
    "            res_start = torch.zeros([1, 2, tgt_emb.shape[-1], src_emb.shape[-1]]).to(self.device)\n",
    "        else:\n",
    "            res_start = src_agg_field\n",
    "            res_start = res_start.from_pixels()\n",
    "            while res_start.shape[-1] < src_emb.shape[-1]:\n",
    "                res_start = res_start.up()\n",
    "            res_start = res_start.pixels()\n",
    "            \n",
    "        pred_res_opt = 0\n",
    "        pred_res_opt = opt(\n",
    "            src_emb.unsqueeze(0), \n",
    "            tgt_emb.unsqueeze(0), \n",
    "            res_start, \n",
    "            src_defects=torch.zeros_like(src_mask, device=self.device), \n",
    "            tgt_defects=torch.zeros_like(src_mask, device=self.device), \n",
    "            lr=2e-1,\n",
    "            sm=self.sm\n",
    "        )\n",
    "        \n",
    "        return src_emb, tgt_emb, pred_res_opt\n",
    "\n",
    "opt_pc_m11 = OptiPrecoarse(mask_value=-1)\n",
    "opt_pc_m9 = OptiPrecoarse(level=-3, sm=15e0, mask_value=-1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_m11 = modelhouse.load_model('gs://corgie/models/fly_m11_precoarse_x0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'src_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2661dd30d550>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msrc_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm11_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_pc_m11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'src_img' is not defined"
     ]
    }
   ],
   "source": [
    "src_emb, tgt_emb, m11_res = opt_pc_m11.forward(src_img=src_img, tgt_img=tgt_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.059300695 0.059300695 0.0\n",
      "New best: 488, No impr: 15, NaN: 0, Iter: 696\n",
      "0.028470099 0.025863677 0.0026064208\n",
      "40.01774787902832\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "src_emb, tgt_emb, m11_res = m_m11.forward(src_img=src_img, tgt_img=tgt_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09536364 0.08659827 0.0087653715\n",
      "New best: 1169, No impr: 15, NaN: 0, Iter: 1550\n",
      "0.0691969 0.061525878 0.007671028\n",
      "34.34898519515991\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "src_emb, tgt_emb, m9_res = opt_pc_m9.forward(src_img=src_img, tgt_img=tgt_img, src_agg_field=m11_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m11_res_ups = m11_res.clone().from_pixels()\n",
    "while m11_res_ups.shape[-1] < src_img.shape[-1]:\n",
    "    m11_res_ups = m11_res_ups.up()\n",
    "    \n",
    "m9_res_ups = m9_res.clone().from_pixels()\n",
    "while m9_res_ups.shape[-1] < src_img.shape[-1]:\n",
    "    m9_res_ups = m9_res_ups.up()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c557150811db41908626bde61ca57b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2, 3), value=0), IntText(value=1, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = [src_img, tgt_img, m11_res_ups(src_img), m9_res_ups(src_img)]\n",
    "simple_visualizer().visualize(v, section_count=1, x_section=0, y_section=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6171546 0.9601498 0.65700483\n",
      "New best: 971, No impr: 4, NaN: 0, Iter: 999\n",
      "1.1762884 0.9326268 0.24366155\n",
      "89.10191082954407\n",
      "==========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'precoarse_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3f1ff7304c95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msrc_agg_field\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm9_res_ups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msrc_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecoarse_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoarse_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msimple_visualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_section\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_section\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'precoarse_img' is not defined"
     ]
    }
   ],
   "source": [
    "coarse_res = test_pyramid(\n",
    "    src_img=src_img, \n",
    "    tgt_img=tgt_img,\n",
    "    src_agg_field=m9_res_ups.pixels()\n",
    ")\n",
    "v = [src_img, tgt_img, precoarse_img, coarse_res.from_pixels()(src_img)]\n",
    "simple_visualizer().visualize(v, section_count=1, x_section=0, y_section=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b64b590a67647d7ab1345a1257421c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2, 3, 4), value=0), IntText(value=1, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = [src_img, tgt_img, m11_res_ups(src_img), m9_res_ups(src_img), coarse_res.from_pixels()(src_img)]\n",
    "simple_visualizer().visualize(v, section_count=1, x_section=0, y_section=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligner_path = '/usr/people/popovych/models/fly_coarse_x0'\n",
    "aligner_params = {\n",
    "  \"checkpoint_name\": \"try_x0_nobn\",\n",
    "  \"finetune\": True,\n",
    "  \"finetune_iter\": 300,\n",
    "  \"finetune_lr\": 0.3,\n",
    "  \"finetune_sm\": 300\n",
    "}\n",
    "coarse_aligner = modelhouse.load_model(\n",
    "    aligner_path, \n",
    "    params=json.dumps(aligner_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aligner(\n",
       "  (net): ScaleNet(\n",
       "    (level_upmodules): ModuleDict(\n",
       "      (0): FmRangeApply(\n",
       "        (module): SplitProcessor(\n",
       "          (processors): ModuleList(\n",
       "            (0): Identity()\n",
       "            (1): TransparentSeq(\n",
       "              (stages): ModuleList(\n",
       "                (0): Sequence(\n",
       "                  (layers): ModuleList(\n",
       "                    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (7): LeakyReLU(negative_slope=0.01)\n",
       "                    (8): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                  (seq): Sequential(\n",
       "                    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (7): LeakyReLU(negative_slope=0.01)\n",
       "                    (8): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): FmRangeApply(\n",
       "        (module): SplitProcessor(\n",
       "          (processors): ModuleList(\n",
       "            (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "            (1): TransparentSeq(\n",
       "              (stages): ModuleList(\n",
       "                (0): Sequence(\n",
       "                  (layers): ModuleList(\n",
       "                    (0): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                  (seq): Sequential(\n",
       "                    (0): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "                (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                (2): Sequence(\n",
       "                  (layers): ModuleList(\n",
       "                    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                  (seq): Sequential(\n",
       "                    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): FmRangeApply(\n",
       "        (module): SplitProcessor(\n",
       "          (processors): ModuleList(\n",
       "            (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "            (1): TransparentSeq(\n",
       "              (stages): ModuleList(\n",
       "                (0): Sequence(\n",
       "                  (layers): ModuleList(\n",
       "                    (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                  (seq): Sequential(\n",
       "                    (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "                (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                (2): Sequence(\n",
       "                  (layers): ModuleList(\n",
       "                    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                  (seq): Sequential(\n",
       "                    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): FmRangeApply(\n",
       "        (module): SplitProcessor(\n",
       "          (processors): ModuleList(\n",
       "            (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "            (1): TransparentSeq(\n",
       "              (stages): ModuleList(\n",
       "                (0): Sequence(\n",
       "                  (layers): ModuleList(\n",
       "                    (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                  (seq): Sequential(\n",
       "                    (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "                (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                (2): Sequence(\n",
       "                  (layers): ModuleList(\n",
       "                    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                  (seq): Sequential(\n",
       "                    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): FmRangeApply(\n",
       "        (module): SplitProcessor(\n",
       "          (processors): ModuleList(\n",
       "            (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "            (1): TransparentSeq(\n",
       "              (stages): ModuleList(\n",
       "                (0): Sequence(\n",
       "                  (layers): ModuleList(\n",
       "                    (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                  (seq): Sequential(\n",
       "                    (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "                (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                (2): Sequence(\n",
       "                  (layers): ModuleList(\n",
       "                    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                  (seq): Sequential(\n",
       "                    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (1): LeakyReLU(negative_slope=0.01)\n",
       "                    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (3): LeakyReLU(negative_slope=0.01)\n",
       "                    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                    (5): LeakyReLU(negative_slope=0.01)\n",
       "                    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (level_downmodules): ModuleDict(\n",
       "      (4): WarpWithInputDownmodule(\n",
       "        (module): Sequential(\n",
       "          (0): Sequence(\n",
       "            (layers): ModuleList(\n",
       "              (0): Conv2d(8, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (1): LeakyReLU(negative_slope=0.01)\n",
       "              (2): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (3): LeakyReLU(negative_slope=0.01)\n",
       "              (4): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (5): LeakyReLU(negative_slope=0.01)\n",
       "              (6): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (7): LeakyReLU(negative_slope=0.01)\n",
       "              (8): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (9): LeakyReLU(negative_slope=0.01)\n",
       "              (10): Conv2d(24, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "            )\n",
       "            (seq): Sequential(\n",
       "              (0): Conv2d(8, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (1): LeakyReLU(negative_slope=0.01)\n",
       "              (2): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (3): LeakyReLU(negative_slope=0.01)\n",
       "              (4): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (5): LeakyReLU(negative_slope=0.01)\n",
       "              (6): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (7): LeakyReLU(negative_slope=0.01)\n",
       "              (8): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (9): LeakyReLU(negative_slope=0.01)\n",
       "              (10): Conv2d(24, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "            )\n",
       "          )\n",
       "          (1): Vectorizer(\n",
       "            (normer): Softmax(dim=-1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): WarpWithInputDownmodule(\n",
       "        (module): Sequential(\n",
       "          (0): Sequence(\n",
       "            (layers): ModuleList(\n",
       "              (0): Conv2d(8, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (1): LeakyReLU(negative_slope=0.01)\n",
       "              (2): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (3): LeakyReLU(negative_slope=0.01)\n",
       "              (4): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (5): LeakyReLU(negative_slope=0.01)\n",
       "              (6): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (7): LeakyReLU(negative_slope=0.01)\n",
       "              (8): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (9): LeakyReLU(negative_slope=0.01)\n",
       "              (10): Conv2d(24, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "            )\n",
       "            (seq): Sequential(\n",
       "              (0): Conv2d(8, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (1): LeakyReLU(negative_slope=0.01)\n",
       "              (2): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (3): LeakyReLU(negative_slope=0.01)\n",
       "              (4): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (5): LeakyReLU(negative_slope=0.01)\n",
       "              (6): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (7): LeakyReLU(negative_slope=0.01)\n",
       "              (8): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (9): LeakyReLU(negative_slope=0.01)\n",
       "              (10): Conv2d(24, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "            )\n",
       "          )\n",
       "          (1): Vectorizer(\n",
       "            (normer): Softmax(dim=-1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (level_uplinks): ModuleDict(\n",
       "      (0): Identity()\n",
       "      (1): Identity()\n",
       "      (2): Identity()\n",
       "      (3): Identity()\n",
       "      (4): Identity()\n",
       "      (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (10): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (12): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (13): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (level_downlinks): ModuleDict(\n",
       "      (0): UpsampleResiduals()\n",
       "      (1): UpsampleResiduals()\n",
       "      (2): UpsampleResiduals()\n",
       "      (3): UpsampleResiduals()\n",
       "      (4): UpsampleResiduals()\n",
       "      (5): UpsampleResiduals()\n",
       "      (6): UpsampleResiduals()\n",
       "      (7): UpsampleResiduals()\n",
       "      (8): UpsampleResiduals()\n",
       "      (9): UpsampleResiduals()\n",
       "      (10): UpsampleResiduals()\n",
       "      (11): UpsampleResiduals()\n",
       "      (12): UpsampleResiduals()\n",
       "      (13): UpsampleResiduals()\n",
       "    )\n",
       "    (level_skiplinks): ModuleDict(\n",
       "      (0): Identity()\n",
       "      (1): Identity()\n",
       "      (2): Identity()\n",
       "      (3): Identity()\n",
       "      (4): Identity()\n",
       "      (5): Identity()\n",
       "      (6): Identity()\n",
       "      (7): Identity()\n",
       "      (8): Identity()\n",
       "      (9): Identity()\n",
       "      (10): Identity()\n",
       "      (11): Identity()\n",
       "      (12): Identity()\n",
       "      (13): Identity()\n",
       "    )\n",
       "    (level_combiners): ModuleDict(\n",
       "      (0): RollbackWarp(\n",
       "        (ups_res): UpsampleResiduals()\n",
       "        (ups_img): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (downs_img): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (1): RollbackWarp(\n",
       "        (ups_res): UpsampleResiduals()\n",
       "        (ups_img): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (downs_img): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (2): RollbackWarp(\n",
       "        (ups_res): UpsampleResiduals()\n",
       "        (ups_img): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (downs_img): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (3): RollbackWarp(\n",
       "        (ups_res): UpsampleResiduals()\n",
       "        (ups_img): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (downs_img): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (4): RollbackWarp(\n",
       "        (ups_res): UpsampleResiduals()\n",
       "        (ups_img): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (downs_img): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (5): RollbackWarp(\n",
       "        (ups_res): UpsampleResiduals()\n",
       "        (ups_img): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (downs_img): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (6): RollbackWarp(\n",
       "        (ups_res): UpsampleResiduals()\n",
       "        (ups_img): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (downs_img): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (7): RollbackWarp(\n",
       "        (ups_res): UpsampleResiduals()\n",
       "        (ups_img): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (downs_img): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (8): RollbackWarp(\n",
       "        (ups_res): UpsampleResiduals()\n",
       "        (ups_img): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (downs_img): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (9): RollbackWarp(\n",
       "        (ups_res): UpsampleResiduals()\n",
       "        (ups_img): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (downs_img): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (10): RollbackWarp(\n",
       "        (ups_res): UpsampleResiduals()\n",
       "        (ups_img): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (downs_img): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (11): RollbackWarp(\n",
       "        (ups_res): UpsampleResiduals()\n",
       "        (ups_img): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (downs_img): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (12): RollbackWarp(\n",
       "        (ups_res): UpsampleResiduals()\n",
       "        (ups_img): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (downs_img): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (13): RollbackWarp(\n",
       "        (ups_res): UpsampleResiduals()\n",
       "        (ups_img): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (downs_img): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_pc.forward(src_img=src_img, tgt_img=tgt_img)\n",
    "opt_pc.embedder.aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/people/popovych/metro_models/pyramid_fly_x2/0_mip7in_mip11module/model/model_spec.json\n",
      "block_6convs_fms8to32_skip25.json\n",
      "categorical/categorical_compch15_gridfalse_maxvalue7_outch2_stepnull_trainsttrue.json\n",
      "block_6convs_fms8to32_skip25.json\n",
      "categorical/categorical_compch15_gridfalse_maxvalue7_outch2_stepnull_trainsttrue.json\n",
      "identity.json\n",
      "embedder_m0_3x3_fms1x.json\n",
      "block_5convs_3x3_fms1to1_skip14.json\n",
      "average_pool.json\n",
      "embedder_fms2to3.json\n",
      "block_3convs_3x3_fms2to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "upsample_residuals.json\n",
      "identity.json\n",
      "Adding 'x10240_y0_z200' dataset.\n",
      "Loading file '/usr/people/popovych/metro_datasets/fly_full_x4_bigtest/x10240_y0_z200_MIP7.h5...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/people/popovych/artificery/artificery/parsers/categorical_regression/parse.py:38: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  requires_grad=False) - self.component_channels//2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab067dbd1984a65b7e91e096671c34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=False, description='Take from validation set'), Checkbox(value=True, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checkpiont = \"spynet_x0\"\n",
    "#checkpoint_folder = \"/usr/people/popovych/metro_models/spynet_m4m6m9/0_mip4in_mip4569module/model\" #\"/usr/people/popovych/aligner/experiments/{}\".format(pyramid_name)\n",
    "\n",
    "#checkpiont = \"rigid_net\"\n",
    "checkpiont = \"full_x2\"\n",
    "#checkpoint_folder = \"/usr/people/popovych/metro_models/pyramid_m4m6m9/0_mip7in_mip9module/model\" #\"/usr/people/popovych/aligner/experiments/{}\".format(pyramid_name)\n",
    "\n",
    "checkpoint_folder = \"/usr/people/popovych/metro_models/pyramid_fly_x2/0_mip7in_mip11module/model\" #\"/usr/people/popovych/aligner/experiments/{}\".format(pyramid_name)\n",
    "\n",
    "#checkpoint_folder = \"/usr/people/popovych/metro_models/pyramid_m4m6m9/2_mip4in_mip4module/model\" #\"/usr/people/popovych/aligner/experiments/{}\".format(pyramid_name)\n",
    "#checkpoint_folder = \"/usr/people/popovych/metro_models/pyramid_m5m9/1_mip4in_mip5module/model\" #\"/usr/people/popovych/aligner/experiments/{}\".format(pyramid_name)\n",
    "\n",
    "test_pyramid = aligner.Aligner(checkpoint_folder, checkpoint_name=checkpiont, train=False, \n",
    "                               finetune_lr=3e-1, finetune_sm=200e0, finetune_iter=200, finetune=True)\n",
    "viz1 = PyramidVisualizer(test_pyramid)\n",
    "run_mip = 0\n",
    "\n",
    "viz1.def_norm_img = True\n",
    "viz1.set_model(test_pyramid)\n",
    "viz1.visualize(section_count=2, default_slice=3227, default_x=0, default_y=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m7_in = test_pyramid.net.state['up']['0']['input']\n",
    "m7_out = test_pyramid.net.state['up']['0']['output']\n",
    "m8_in = test_pyramid.net.state['up']['1']['input']\n",
    "m8_out = test_pyramid.net.state['up']['1']['output']\n",
    "m9_in = test_pyramid.net.state['up']['2']['input']\n",
    "m9_out = test_pyramid.net.state['up']['2']['output']\n",
    "m10_in = test_pyramid.net.state['up']['3']['input']\n",
    "m10_out = test_pyramid.net.state['up']['3']['output']\n",
    "m11_in = test_pyramid.net.state['up']['4']['input']\n",
    "m11_out = test_pyramid.net.state['up']['4']['output']\n",
    "v = [m7_out[0, 0], m8_out[0, 0],  m9_out[0, 0], m11_out[0, 0], m11_out[0, 1],\n",
    "     m7_out[0, 1], m8_out[0, 1],  m9_out[0, 1], m11_out[0, 1], m11_out[0, 1],\n",
    "     m7_out[0, 2], m8_out[0, 5],  m9_out[0, 5], m11_out[0, 4], m11_out[0, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e21a1262084adf99167dd34eb74b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "simple_visualizer().visualize(v, section_count=1, x_section=0, y_section=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/people/popovych/.modelhouse/tmp_files/tmp2jpa6i9h/model/model_spec.json\n",
      "block_6convs_fms8to32_skip25.json\n",
      "categorical/categorical_compch15_gridfalse_maxvalue7_outch2_stepnull_trainsttrue.json\n",
      "block_6convs_fms8to32_skip25.json\n",
      "categorical/categorical_compch15_gridfalse_maxvalue7_outch2_stepnull_trainsttrue.json\n",
      "identity.json\n",
      "embedder_m0_3x3_fms1x.json\n",
      "block_5convs_3x3_fms1to1_skip14.json\n",
      "average_pool.json\n",
      "embedder_fms2to3.json\n",
      "block_3convs_3x3_fms2to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/people/popovych/artificery/artificery/parsers/categorical_regression/parse.py:38: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  requires_grad=False) - self.component_channels//2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "upsample_residuals.json\n",
      "identity.json\n"
     ]
    }
   ],
   "source": [
    "import modelhouse\n",
    "model_path = \"gs://tmacrina-corgie-test/models/pyramid_fly_x2_210223_tmacrina_blockmatched_iters118/0_mip7in_mip11module\"\n",
    "model_checkpoint = \"try_x0_nobn\"\n",
    "model = modelhouse.load_model(model_path, params=json.dumps({'checkpoint_name': model_checkpoint, 'finetune': False})).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res_start = torch.cuda.FloatTensor(viz1.vect_dict['Predicted Residual']).unsqueeze(0).field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1792, 1792]) torch.Size([1792, 1792])\n",
      "torch.Size([1, 1792, 1792]) torch.Size([1792, 1792])\n"
     ]
    }
   ],
   "source": [
    "embedder = modelhouse.uncached_load_model_str(\n",
    "    '/usr/people/popovych/models/embedder',\n",
    "    params=json.dumps({\n",
    "        'model_path': model_path,\n",
    "        'model_checkpoint': model_checkpoint,\n",
    "        'level': 0\n",
    "    })\n",
    ")\n",
    "src_img = m7_out[0, 0]\n",
    "src_emb = embedder(src_img)[0]\n",
    "tgt_img = m7_out[0, 2]\n",
    "tgt_emb = embedder(tgt_img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_emb_warp = pred_res_start.from_pixels()(src_emb)\n",
    "src_img_warp = pred_res_start.from_pixels()(src_img)\n",
    "diff = (src_emb_warp - tgt_emb)**2\n",
    "diff[src_emb_warp == 0] = 0\n",
    "diff[tgt_emb == 0] = 0\n",
    "diff = metroem.helpers.get_np(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "misd = modelhouse.uncached_load_model(\"/usr/people/popovych/models/misalign_detect_fafb_m7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_mask = misd(tgt_img, src_img_warp)\n",
    "\n",
    "v = [\n",
    "    mis_mask,\n",
    "    tgt_img,\n",
    "    src_img_warp,\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80370a1a86ee4bcf9614c253df1d10f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2), value=0), IntText(value=1, descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_visualizer().visualize(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_pixels = (downup(diff, 3) > 1).astype(np.float32)\n",
    "bad_pixels = diff > 1\n",
    "bad_pixels_d = bad_pixels\n",
    "for i in range(1):\n",
    "    bad_pixels_d = dilate(bad_pixels_d)\n",
    "bad_pixels_d = closing(bad_pixels_d, n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1792, 1792)\n",
      "(1792, 1792)\n"
     ]
    }
   ],
   "source": [
    "import cc3d\n",
    "import numpy as np\n",
    "import fastremap \n",
    "print (bad_pixels_d.shape)\n",
    "cc_labels = cc3d.connected_components(bad_pixels_d)\n",
    "segids, counts = np.unique(cc_labels, return_counts=True)\n",
    "segids = [ segid for segid, ct in zip(segids, counts) if ct > 100 ]\n",
    "filtered_mask = fastremap.mask_except(cc_labels, segids, in_place=True) != 0\n",
    "\n",
    "for i in range(3): \n",
    "    filtered_mask = dilate(filtered_mask)\n",
    "    \n",
    "filtered_mask = closing(filtered_mask, n=6)\n",
    "filtered_mask[diff == 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1792, 1792)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caad001fbfe548de9b95578ffc8e11fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8), value=0), IntTe…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = [\n",
    "    \n",
    "    tgt_img,\n",
    "    src_img_warp,\n",
    "    filtered_mask,\n",
    "    diff,\n",
    "    bad_pixels,\n",
    "    bad_pixels_d,\n",
    "    cc_labels,\n",
    "    downup(bad_pixels, 30, ignore_zeros=False),\n",
    "    m7_out[0, 0]\n",
    "]\n",
    "simple_visualizer().visualize(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbdbe8ac4da45ecadf89061fe409c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2), value=0), IntText(value=1, descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = [\n",
    "    model.aligner.get_embeddings(m7_out[0, 0], 2, True)[0],\n",
    "    model.aligner.get_embeddings(m7_out[0, 2], 2, True)[0],\n",
    "    m7_out[0, 0]\n",
    "]\n",
    "simple_visualizer().visualize(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/people/popovych/env/corgie/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd768ebabb54319847e698794f71eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), value=0), In…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from metroem import masks\n",
    "from metroem import helpers\n",
    "src = m11_out[0, 1:4]\n",
    "tgt = m11_out[0, 5:8]\n",
    "\n",
    "\n",
    "src_mask = m11_out[0, 0] == 0\n",
    "src_mask = masks.coarsen_mask(src_mask.float(), flip=False).squeeze() != 0\n",
    "tgt_mask = m11_out[0, 4] == 0\n",
    "tgt_mask = masks.coarsen_mask(tgt_mask.float(), flip=False).squeeze() != 0\n",
    "src[:, src_mask] = -1\n",
    "tgt[:, tgt_mask] = -1\n",
    "\n",
    "m0_out = test_pyramid.net.state['up']['0']['output']\n",
    "pred_res_start = torch.cuda.FloatTensor(viz1.vect_dict['Predicted Residual']).unsqueeze(0).field()\n",
    "\n",
    "pred_res_start = pred_res_start.from_pixels()\n",
    "for _ in range(4):\n",
    "    pred_res_start =  pred_res_start.down()\n",
    "pred_res_start = pred_res_start.pixels()\n",
    "\n",
    "\n",
    "src_defects = m11_out[0, 0] == 0\n",
    "tgt_defects = m11_out[0, 4] == 0\n",
    "\n",
    "v = [src[0], src[1], src[2], src_defects, src[0],\n",
    "    tgt[0], tgt[1], tgt[2], tgt_defects, tgt[0],]\n",
    "simple_visualizer().visualize(v, section_count=1, x_section=0, y_section=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.7833, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM: 20.0\n",
      "torch.Size([1, 3, 112, 112])\n",
      "tensor(-0.7813, device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "0.059300695 0.059300695 0.0\n",
      "New best: 737, No impr: 15, NaN: 0, Iter: 1003\n",
      "0.026290828 0.023430608 0.0028602195\n",
      "27.5064640045166\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "from metroem import finetuner\n",
    "from metroem import masks\n",
    "importlib.reload(finetuner)\n",
    "importlib.reload(masks)\n",
    "from metroem.finetuner import optimize_pre_post_ups\n",
    "'''\n",
    "       'src': [\n",
    "            {'name': 'src',\n",
    "             'fm': 0,\n",
    "             \"coarsen_ranges\": [ (0, 0)],\n",
    "             'binarization': {'strat': 'neq', 'value': 0},\n",
    "             }\n",
    "            ],\n",
    "        'tgt':[\n",
    "            {'name': 'tgt',\n",
    "             'fm': 0,\n",
    "            'binarization': {'strat': 'neq', 'value': 0},\n",
    "             \"coarsen_ranges\": [ (0, 0)]\n",
    "             }\n",
    "        ]   \n",
    "'''\n",
    "def overfit_opt(src, tgt, pred_res_start, src_defects=None, tgt_defects=None, lr=18e-1):\n",
    "    \n",
    "    mse_keys_to_apply = {\n",
    "\n",
    "    }\n",
    "    sm_keys_to_apply = {  \n",
    "        'src': [\n",
    "            {'name': 'src',\n",
    "             'fm': 0,\n",
    "             \"coarsen_ranges\": [ (0, 0)],\n",
    "             'binarization': {'strat': 'neq', 'value': -1},\n",
    "             }\n",
    "            ],\n",
    "        'tgt': [\n",
    "            {'name': 'tgt',\n",
    "             'fm': 0,\n",
    "             \"coarsen_ranges\": [ (0, 0)],\n",
    "             'binarization': {'strat': 'neq', 'value': -1},\n",
    "             }\n",
    "            ],\n",
    "                                                                                                        \n",
    "   }\n",
    "    sm_keys_to_apply['tgt'] = {}\n",
    "    \n",
    "    src_small_defects = None\n",
    "    src_large_defects = None\n",
    "    \n",
    "        \n",
    "    if src_small_defects is not None:\n",
    "        src_small_defects = src_small_defects.squeeze(0)\n",
    "    else:\n",
    "        src_small_defects = torch.zeros_like(src)\n",
    "        \n",
    "    if src_large_defects is not None:\n",
    "        src_large_defects = src_large_defects.squeeze(0)\n",
    "    else:\n",
    "        src_large_defects = torch.zeros_like(src)\n",
    "    sm_f = 1.0\n",
    "    sm = 2e1#1200/pred_res_start.abs().max() * sm_f\n",
    "    \n",
    "    print (f\"SM: {sm}\")\n",
    "    print (src.shape)\n",
    "    print (src.mean())\n",
    "    print (res_start.mean())\n",
    "    pred_res_opt = optimize_pre_post_ups(src, tgt, pred_res_start,\n",
    "            src_defects=torch.zeros_like(src_defects),\n",
    "            tgt_defects=torch.zeros_like(tgt_defects),\n",
    "            crop=4, num_iter=10000,\n",
    "            opt_res_coarsness=0,\n",
    "            sm_keys_to_apply=sm_keys_to_apply,\n",
    "            mse_keys_to_apply=mse_keys_to_apply,\n",
    "            normalize=False,\n",
    "            sm=sm, lr=lr)\n",
    "    return pred_res_opt\n",
    "res_start = torch.zeros_like(pred_res_start)\n",
    "#res_start = pred_res_start\n",
    "pred_res_opt = overfit_opt(src.unsqueeze(0), tgt.unsqueeze(0), res_start, src_defects=src_defects, tgt_defects=tgt_defects, \n",
    "                           lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31886f2eab66477bae7925a4b6152afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), value=0), In…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_opt = pred_res_opt.field().from_pixels()(src.unsqueeze(0)).squeeze()\n",
    "src_init = pred_res_start.field().from_pixels()(src.unsqueeze(0)).squeeze()\n",
    "v = [src[0], tgt[0], src_opt[0], src_init[0], torch.zeros_like(src[0]),\n",
    "    src[1], tgt[1], src_opt[1], src_init[1], torch.zeros_like(src[0])]\n",
    "simple_visualizer().visualize(v, section_count=1, x_section=0, y_section=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_opt = pred_res_opt.field().from_pixels()(src.unsqueeze(0)).squeeze()\n",
    "src_init = pred_res_start.field().from_pixels()(src.unsqueeze(0)).squeeze()\n",
    "v = [src[0] == 0, m11_out[0, 0] == 0]\n",
    "simple_visualizer().visualize(v, section_count=1, x_section=0, y_section=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print (((src[i] - tgt[i]) ** 2).mean(), ((src_opt[i] - tgt[i]) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_res_opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4f45cbf34ecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mopt_res_warp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_res_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_res_opt' is not defined"
     ]
    }
   ],
   "source": [
    "src_img = m7_out[0, 0]\n",
    "tgt_img = m7_out[0, 2]\n",
    "\n",
    "\n",
    "opt_res_warp = pred_res_opt.field().from_pixels()\n",
    "\n",
    "for _ in range(4):\n",
    "    opt_res_warp =  opt_res_warp.up()\n",
    "opt_res_warp = opt_res_warp.pixels()\n",
    "\n",
    "src_opt_img = opt_res_warp.field().from_pixels()(src_img.unsqueeze(0).unsqueeze(0)).squeeze()\n",
    "#src_init = pred_res_start.field().from_pixels()(src.unsqueeze(0)).squeeze()\n",
    "\n",
    "v = [src_opt_img, tgt_img, src_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061f8584f777473bb06222b13875da95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2), value=0), IntText(value=2, descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_visualizer().visualize(v, section_count=2, x_section=0, y_section=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corgie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
