{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from six import iteritems\n",
    "import shelve\n",
    "from scipy.ndimage.measurements import label\n",
    "import h5py\n",
    "import json\n",
    "import sys \n",
    "import operator \n",
    "from scipy import ndimage\n",
    "\n",
    "from pdb import set_trace as st\n",
    "import copy\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "from IPython.html.widgets import interact, fixed\n",
    "from IPython.html import widgets\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from os.path import expanduser\n",
    "import time\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.nn.parallel import data_parallel\n",
    "from torchvision import transforms\n",
    "\n",
    "import random\n",
    "import six\n",
    "\n",
    "import importlib\n",
    "\n",
    "import artificery\n",
    "import metroem\n",
    "importlib.reload(metroem)\n",
    "import torchfields\n",
    "\n",
    "from metroem import loss\n",
    "from metroem import masks\n",
    "from metroem import alignment\n",
    "from metroem import aligner\n",
    "from metroem import train\n",
    "from metroem import helpers\n",
    "from metroem import dataset\n",
    "\n",
    "importlib.reload(helpers)\n",
    "importlib.reload(aligner)\n",
    "importlib.reload(alignment)\n",
    "importlib.reload(masks)\n",
    "importlib.reload(loss)\n",
    "importlib.reload(train)\n",
    "importlib.reload(dataset)\n",
    "\n",
    "from metroem.alignment import align_sample\n",
    "from metroem.loss import similarity_score, smoothness_penalty, get_dataset_loss, get_mse_and_smoothness_masks, smoothness_score\n",
    "from metroem.helpers import reverse_dim, downsample\n",
    "\n",
    "def visualize_residuals(res, figsize=(10,10), x_coords=None, y_coords=None, vec_grid=50):\n",
    "    res = prepare_for_show(res)\n",
    "    if res.shape[0] == 2:\n",
    "        res = np.transpose(res, (1, 2, 0))\n",
    "\n",
    "    assert res.shape[0] == res.shape[1]\n",
    "    plt.figure(figsize=figsize)\n",
    "    n = res.shape[0]\n",
    "    y, x = np.mgrid[0:n, 0:n]\n",
    "    \n",
    "    if x_coords is None:\n",
    "        x_coords = [0, res.shape[0]]\n",
    "    if y_coords is None:\n",
    "        y_coords = [0, res.shape[1]]\n",
    "    \n",
    "    ex = (1) * res[:, :, 0]\n",
    "    ey = res[:, :, 1]\n",
    "    r = np.arctan2(ex, ey)\n",
    "    \n",
    "    interval = (x_coords[1] - x_coords[0]) // vec_grid\n",
    "    \n",
    "    plt.quiver(  x[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval],  \n",
    "                 y[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval],\n",
    "                ex[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval], \n",
    "                ey[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval], \n",
    "                 r[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval], alpha=0.6)\n",
    "    plt.quiver(x[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval],  \n",
    "                 y[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval],\n",
    "                ex[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval], \n",
    "                ey[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval], edgecolor='k', facecolor='None', linewidth=.5)\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "def visualize_histogram(data, figsize=(10,10), x_coords=None, y_coords=None):\n",
    "    pass\n",
    "    \n",
    "def get_np(pt):\n",
    "    return pt.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def prepare_for_show(img):\n",
    "    if isinstance(img, torch.Tensor):\n",
    "         img = get_np(img)\n",
    "    img = img.squeeze()\n",
    "    return img\n",
    "\n",
    "\n",
    "rand_cmap = matplotlib.colors.ListedColormap(np.random.rand(256*32,3))\n",
    "\n",
    "def display_image(img, x_coords=None, y_coords=None, normalize=False, figsize=(10, 10), mask=False, segmentation=False):\n",
    "    if normalize and mask:\n",
    "        raise Exception(\"Masks can't be normalized\")\n",
    "    img = prepare_for_show(img)\n",
    "\n",
    "    if len(img.shape) == 3 and img.shape[-1] == 2:\n",
    "        visualize_residuals(img, x_coords=x_coords, y_coords=y_coords)\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    if x_coords is None:\n",
    "        x_coords = [0, img.shape[0]]\n",
    "    if y_coords is None:\n",
    "        y_coords = [0, img.shape[1]]\n",
    "    \n",
    "    if mask:\n",
    "        plt.imshow(img[x_coords[0]:x_coords[1], y_coords[0]:y_coords[1]], cmap='gray')\n",
    "    elif segmentation:\n",
    "        cmap='gray'\n",
    "        cmap = rand_cmap\n",
    "        \n",
    "        plt.imshow(img[x_coords[0]:x_coords[1], y_coords[0]:y_coords[1]].astype(np.int32), cmap=cmap)\n",
    "    elif not normalize:\n",
    "        plt.imshow(img[x_coords[0]:x_coords[1], y_coords[0]:y_coords[1]], cmap='gray', vmin=-1.5, vmax=1.5)\n",
    "    else:\n",
    "        plt.imshow(img[x_coords[0]:x_coords[1], y_coords[0]:y_coords[1]], cmap='gray')\n",
    "\n",
    "        \n",
    "def precompute_state(self, img_id, sup, val, state_file):\n",
    "    self.compute_state(img_id, sup, val)\n",
    "    try:\n",
    "        \n",
    "        state_h5 = h5py.File(state_file, 'w')\n",
    "        img_shape = self.src.shape\n",
    "        dset_shape = [0, 100, img_shape[3], img_shape[4]]\n",
    "        if \"main\" not in state_h5:\n",
    "            src_h5 = state_h5.create_dataset(\"main/src\", dset_shape)\n",
    "            tgt_h5 = state_h5.create_dataset(\"main/tgt\", dset_shape)\n",
    "            pred_tgt_h5 = state_h5.create_dataset(\"main/pred_tgt_h5\", dset_shape)\n",
    "        else:\n",
    "            src_h5 = state_h5[\"main/src\"]\n",
    "            tgt_h5 = state_h5[\"main/tgt\"]\n",
    "            pred_tgt_h5 = state_h5[\"main/pred_tgt\"]\n",
    "        src_h5[:, img_id:img_id+1, :, :] = 0#self.src \n",
    "        tgt_h5[:, img_id:img_id+1, :, :] = 0#self.tgt\n",
    "        pred_tgt_h5[:, img_id:img_id+1, :, :] = 0#self.pred_tgt_h5\n",
    "        state_h5.close()\n",
    "    except Exception as e:\n",
    "        state_h5.close()\n",
    "        raise e\n",
    "\n",
    "def filter_folds(viz_mse_mask_var, input_mip=6):\n",
    "    downsampler = nn.AvgPool2d(2) \n",
    "    for i in range(input_mip, 8):\n",
    "        viz_mse_mask_var = downsampler(viz_mse_mask_var)\n",
    "        \n",
    "    viz_mse_mask_var = (viz_mse_mask_var < 0.3).type(torch.cuda.DoubleTensor)\n",
    "                           \n",
    "    viz_mse_mask_var = viz_mse_mask_var.type(torch.cuda.ByteTensor)\n",
    "    mse_mask_np = get_np(viz_mse_mask_var.squeeze())\n",
    "    filtered_mse_mask_np = filter_connected_component(mse_mask_np, 100) == 0\n",
    "    return filtered_mse_mask_np\n",
    "\n",
    "        \n",
    "def segment_folds(fold_mask_np, memory_limit=None):\n",
    "    initial_segments = get_initial_segments(fold_mask_np, memory_limit)\n",
    "    segments  = cleanup_segment_stripes(initial_segments, n=16)\n",
    "    return segments\n",
    "\n",
    "def cleanup_segment_stripes(segments, n):\n",
    "    seg_t = np.copy(segments.T)\n",
    "    seg_start = np.zeros_like(seg_t[0])\n",
    "    last_seg = np.zeros_like(seg_t[1])\n",
    "    last_cleanup = 0\n",
    "    \n",
    "    for i in range(1, seg_t.shape[0]): \n",
    "        is_fold = seg_t[i] == 0\n",
    "        was_fold = seg_t[i - 1] == 0\n",
    "        last_seg_fold = last_seg == 0\n",
    "        \n",
    "        new_seg = (seg_t[i] != seg_t[i - 1])\n",
    "        seg_width = i - seg_start\n",
    "        \n",
    "        bad_seg = new_seg * (seg_width < n) * (was_fold == False) * (is_fold == False)\n",
    "        bad_seg_names = np.unique(seg_t[i - 1][bad_seg])\n",
    "        \n",
    "        if len(bad_seg_names) > 0:\n",
    "            print (i, last_cleanup, bad_seg_names)\n",
    "            cleanup_seg_id = i - 2\n",
    "            ref_seg_id = i - 1\n",
    "\n",
    "            ids_to_clean = None\n",
    "            change_to_these = np.maximum(last_seg, new_seg)\n",
    "            while (cleanup_seg_id >= 0):\n",
    "                ids_to_clean = (seg_t[cleanup_seg_id] == seg_t[ref_seg_id]) * bad_seg * (last_seg_fold == False)\n",
    "                if np.any(ids_to_clean) == False:\n",
    "                    break\n",
    "                seg_t[cleanup_seg_id][ids_to_clean] = change_to_these[ids_to_clean]\n",
    "                cleanup_seg_id -= 1\n",
    "            seg_t[ref_seg_id][bad_seg * (last_seg_fold == False)] = change_to_these[bad_seg * (last_seg_fold == False)]\n",
    "            last_cleanup = i\n",
    "                                  \n",
    "        last_seg[new_seg] = seg_t[i - 1][new_seg]\n",
    "        seg_start[new_seg] = i\n",
    "    return seg_t.T\n",
    "\n",
    "def get_initial_segments(fold_mask_np, memory_limit, smallest_seg):\n",
    "    folds = fold_mask_np == False\n",
    "    segments = np.zeros_like(folds, dtype=np.int32)\n",
    "    last_fold = np.zeros_like(folds[0], dtype=np.int32)\n",
    "    seg_start = np.zeros_like(folds[0], dtype=np.int32)\n",
    "    \n",
    "    segments[0] = 1\n",
    "    segments[0][folds[0]] = 0\n",
    "    max_in_line = np.copy(segments[0])\n",
    "    \n",
    "    \n",
    "    for i in range(1, folds.shape[0]):\n",
    "        \n",
    "        \n",
    "        is_fold = folds[i]\n",
    "        was_fold = folds[i - 1]\n",
    "        curr_seg = segments[i]\n",
    "        last_seg = segments[i - 1]\n",
    "        \n",
    "        continue_ids = (is_fold == False) * (was_fold == False)\n",
    "        short_stretch = (i - seg_start) < smallest_seg\n",
    "        \n",
    "        new_seg_ids = (is_fold == False) * (was_fold == True) * (short_stretch == False)\n",
    "        jump_seg_ids = (is_fold == False) * (was_fold == True) * (short_stretch == True)\n",
    "        \n",
    "        curr_seg[continue_ids] = last_seg[continue_ids]\n",
    "        curr_seg[new_seg_ids] = (max_in_line + 1)[new_seg_ids]\n",
    "        \n",
    "        fresh_start_ids = max_in_line == 0\n",
    "        curr_seg[jump_seg_ids * (fresh_start_ids == False)] = max_in_line[jump_seg_ids * (fresh_start_ids == False)]\n",
    "        curr_seg[jump_seg_ids * (fresh_start_ids == True)] = (max_in_line + 1)[jump_seg_ids * (fresh_start_ids == True)]\n",
    "        \n",
    "        seg_start[new_seg_ids] = i\n",
    "        \n",
    "        curr_seg[is_fold == True] = 0\n",
    "        max_in_line = np.maximum(max_in_line, curr_seg)\n",
    "        \n",
    "        '''if memory_limit is not None:\n",
    "            forgotten_folds = (i - last_fold) > memory_limit\n",
    "            max_in_line[forgotten_folds] = np.maximum(1, max_in_line[forgotten_folds] - 1)'''\n",
    "        last_fold[is_fold] = i\n",
    "        \n",
    "    return segments \n",
    "\n",
    "def expand_mask(mask_np, n=33):\n",
    "    mask_var = torch.FloatTensor(mask_np.astype(np.float)).unsqueeze(0).unsqueeze(0)\n",
    "    kernel = torch.ones([1, 1, n, n])\n",
    "    expanded_mask = torch.nn.functional.conv2d(mask_var, kernel, padding=n//2) \n",
    "    expanded_mask_np = get_np(expanded_mask[0, 0]) > 0\n",
    "    return expanded_mask_np\n",
    "\n",
    "class PyramidVisualizer(object):\n",
    "    def __init__(self, pyramid, def_sup=False):\n",
    "        self.reverse = True\n",
    "        self.fold_size = None\n",
    "        self.src = None\n",
    "        self.prev_id = -1\n",
    "        self.prev_is_val = False\n",
    "        self.prev_is_sup = False\n",
    "        self.val_dataset = None\n",
    "        self.train_dataset = None\n",
    "        self.def_sup = True\n",
    "        self.def_norm_img = False\n",
    "        self.viz_mip = 0\n",
    "        self.run_mip = 0\n",
    "        self.sup = False\n",
    "        self.prerun_augment = []\n",
    "        \n",
    "        self.pyramid = pyramid\n",
    "        self.run_mip = 0\n",
    "        self.viz_mip = 0\n",
    "        \n",
    "        \n",
    "        self.dataset_mip, self.sup_train_dataset = get_datasets()\n",
    "        #self.upsampler = nn.UpsamplingBilinear2d(scale_factor=2)   \n",
    "        self.mse_keys_to_apply = {\n",
    "        'src': [\n",
    "            {'name': 'src_defects',\n",
    "             'binarization': {'strat': 'eq', 'value': 0},\n",
    "             \"not_coarsen_ranges\": [ (0,25)] },\n",
    "            {'name': 'src',\n",
    "             \"not_coarsen_ranges\": [(1, 0)],\n",
    "             'binarization': {'strat': 'neq', 'value': 0}\n",
    "             }\n",
    "            ],\n",
    "        'tgt':[\n",
    "            {'name': 'tgt_defects',\n",
    "             'binarization': {'strat': 'eq', 'value': 0},\n",
    "             \"coarsen_ranges\": [(0, 0)]},\n",
    "            {'name': 'tgt',\n",
    "             \"not_coarsen_ranges\": [(10, 0)],\n",
    "             'binarization': {'strat': 'neq', 'value': 0}\n",
    "             }\n",
    "        ]\n",
    "    }\n",
    "        self.sm_keys_to_apply = {                                                                                                 \n",
    "           \"src\": [                                                                                                          \n",
    "               {\"name\": \"src_defects\",                                                                                      \n",
    "                \"binarization\": {\"strat\": \"eq\", \"value\": 0},                                                               \n",
    "                \"not_coarsen_ranges\": [[1, 0.2], [4, 5.0]],                                                             \n",
    "                \"mask_value\": 1.0e-5},                                                                                       \n",
    "             {\"name\": \"src\",                                                                                             \n",
    "                \"fm\": 0,                                                                                                  \n",
    "                \"binarization\": {\"strat\": \"neq\", \"value\": 0}}                                                            \n",
    "           ],                                                                                                              \n",
    "           \"tgt\":[                                                                                                        \n",
    "               {\"name\": \"tgt_defects\",                                                                                   \n",
    "                \"binarization\": {\"strat\": \"eq\", \"value\": 0},                                                                 \n",
    "                #\"not_coarsen_ranges\": [[1, 0.2], [2, 0.4], [3, 0.6], [4, 0.8]],                                                              \n",
    "                \"mask_value\": 0.0e-5}                                                                                         \n",
    "           ]                                                                                                              \n",
    "       }\n",
    "        \n",
    "    \n",
    "        \n",
    "    def set_model(self, model):\n",
    "        self.pyramid = model\n",
    "        self.prev_id = -1\n",
    "    \n",
    "    def update_state(self, img_id, sup, val, state_file):\n",
    "        if state_file is None:\n",
    "            \n",
    "            self.compute_state(img_id, sup, val)\n",
    "        else:\n",
    "            self.load_state(img_id, sup, val, state_file)\n",
    "            \n",
    "    def compute_state(self, img_id, sup, val):\n",
    "        self.dataset = self.sup_train_dataset\n",
    "                \n",
    "        if self.prev_id == -1:\n",
    "            self.clean_up()\n",
    "            \n",
    "        #make it refresh when sup is changed\n",
    "        if self.prev_id == -1 or self.prev_is_sup != sup:\n",
    "            self.prev_is_sup = sup\n",
    "            self.prev_id = -1\n",
    "            \n",
    "\n",
    "        if img_id != self.prev_id or self.prev_is_val != val:\n",
    "            self.prev_id = img_id\n",
    "            self.prev_is_val = val\n",
    "            #clean_sample = self.dataset[img_id][:, 2:-30, 2:-30].unsqueeze(0)\n",
    "            \n",
    "            raw_sample = copy.deepcopy(self.dataset[img_id])\n",
    "           \n",
    "            for aug in self.prerun_augment:\n",
    "                if aug['type'] == 'contrast_half_src':\n",
    "                    src = raw_sample[0, 0]\n",
    "                    src[src.shape[0]//2:, :] *= aug['mult']\n",
    "                elif aug['type'] == 'brightness_half_src':\n",
    "                    src = raw_sample[0, 0]\n",
    "                    src[src.shape[0]//2:, :] += aug['bump']\n",
    "                else:\n",
    "                    raise Exception(\"Unknown prerun transofm\")\n",
    "                    \n",
    "            for k, v in six.iteritems(raw_sample):\n",
    "                #print (v.shape)\n",
    "                # why are we doing this\n",
    "                raw_sample[k] = v.unsqueeze(0)  \n",
    "                \n",
    "            run_sample = copy.deepcopy(raw_sample)\n",
    "            self.run_sample = run_sample\n",
    "            for k, v in six.iteritems(run_sample):\n",
    "                #print (v.shape)\n",
    "                # why are we doing this: to have the same orientation as ng\n",
    "                #run_sample[k] = v.permute(0, 2, 1)\n",
    "                pass\n",
    "            \n",
    "            model_run_params = {\"level_in\": self.run_mip}\n",
    "            \n",
    "            run_result = align_sample(self.pyramid, run_sample)\n",
    "            for k, v in six.iteritems(run_result):\n",
    "                if hasattr(v, 'detach'):\n",
    "                    run_result[k] = v.detach()\n",
    "                \n",
    "            run_src_var = run_result['src'].unsqueeze(0)                                                                   \n",
    "            run_tgt_var = run_result['tgt'].unsqueeze(0)                                                                                                                             \n",
    "            run_pred_res_var = run_result['pred_res']                                                                \n",
    "            del run_result\n",
    "            \n",
    "            '''run_result = self.pyramid.run_pair(run_sample.unsqueeze(0), self.run_mip, reverse=self.reverse)\n",
    "            run_src_var, run_tgt_var, run_true_res_var, run_pred_res_var, run_pred_tgt_var, run_masks_var = run_result\n",
    "            \n",
    "            del run_result, run_true_res_var, run_pred_tgt_var, run_masks_var'''\n",
    "            \n",
    "            #clean_smale = self.dataset[img_id][:, 2:-30, 2:-30].unsqueeze(0)\n",
    "            viz_sample = copy.deepcopy(raw_sample)\n",
    "                    \n",
    "            viz_src_var = viz_sample['src']\n",
    "            viz_tgt_var = viz_sample['tgt']\n",
    "            \n",
    "            if self.sup:\n",
    "                viz_true_res_var = viz_sample['res']\n",
    "\n",
    "            viz_src_var = viz_src_var\n",
    "            viz_tgt_var = viz_tgt_var\n",
    "            \n",
    "            \n",
    "            viz_pred_res_var = run_pred_res_var#.permute(0, 2, 1, 3).flip(3)\n",
    "            \n",
    "            viz_pred_res_var = viz_pred_res_var.squeeze()\n",
    "            viz_sample['pred_res'] = viz_pred_res_var\n",
    "            \n",
    "            if 'src_field' in viz_sample:\n",
    "                src_res_var = viz_sample['src_field'].field()\n",
    "            else:\n",
    "                src_res_var = torch.zeros_like(run_pred_res_var).field()\n",
    "                \n",
    "            viz_warped_src_var = src_res_var.from_pixels()(viz_src_var)\n",
    "            viz_pred_tgt_var = viz_pred_res_var.from_pixels()(viz_src_var)\n",
    "            \n",
    "            viz_sample['pred_tgt'] = viz_pred_tgt_var\n",
    "\n",
    "\n",
    "            viz_mse_mask_var, viz_smoothness_mask_var = get_mse_and_smoothness_masks(viz_sample, \n",
    "                                                                                     mse_keys_to_apply=self.mse_keys_to_apply,\n",
    "                                                                                    sm_keys_to_apply=self.sm_keys_to_apply)\n",
    "            \n",
    "            \n",
    "            self.viz_sample = viz_sample\n",
    "            # Todo: visualize different penalties\n",
    "            \n",
    "            viz_rigidity_penalty_var = loss.rigidity(viz_pred_res_var.unsqueeze(0))\n",
    "            viz_smoothness_penalty_var = viz_rigidity_penalty_var\n",
    "            \n",
    "            norm_tgt_var = torch.nn.InstanceNorm2d(1)(viz_tgt_var.unsqueeze(0))\n",
    "            norm_pred_tgt_var = torch.nn.InstanceNorm2d(1)(viz_pred_tgt_var.unsqueeze(0))\n",
    "            viz_masked_nrom_diff_var = viz_mse_mask_var * torch.abs(viz_tgt_var - viz_pred_tgt_var)\n",
    "            del norm_tgt_var, norm_pred_tgt_var\n",
    "            \n",
    "            viz_diff_var = (viz_tgt_var - viz_pred_tgt_var)**2\n",
    "            viz_masked_diff_var = viz_diff_var * viz_mse_mask_var\n",
    "            viz_inv_res = torch.zeros_like(viz_pred_res_var)\n",
    "            combined_identity_var = viz_inv_res\n",
    " \n",
    "            self.img_dict = {\n",
    "                'Source': {\"img\": get_np(viz_src_var), \"norm\": self.def_norm_img},\n",
    "                'Warped Source': {\"img\": get_np(viz_warped_src_var), \"norm\": self.def_norm_img},\n",
    "                'Target': {\"img\": get_np(viz_tgt_var), \"norm\": self.def_norm_img},\n",
    "                'Predicted Target': {\"img\": get_np(viz_pred_tgt_var), \"norm\": self.def_norm_img},\n",
    "                'Diff': {\"img\": get_np(viz_diff_var), \"norm\": self.def_norm_img},\n",
    "                'Masked Diff': {\"img\": get_np(viz_masked_diff_var),\n",
    "                                \"norm\": self.def_norm_img},\n",
    "                'MSE Mask': {\"img\": get_np(viz_mse_mask_var)},\n",
    "                'Masked Norm Diff': {\"img\": get_np(viz_masked_nrom_diff_var), \"norm\": self.def_norm_img},\n",
    "                'Smoothness': {\"img\": get_np(viz_smoothness_penalty_var), \"norm\": self.def_norm_img},\n",
    "                'Rigidity': {\"img\": get_np(viz_rigidity_penalty_var), \"norm\": self.def_norm_img},\n",
    "                'Smoothness Mask': {\"img\": get_np(viz_smoothness_mask_var)},\n",
    "                'Masked Smoothness': {\"img\": get_np(viz_smoothness_mask_var * viz_smoothness_penalty_var), \n",
    "                                      \"norm\": self.def_norm_img},\n",
    "                'Masked Rigidity': {\"img\": get_np(viz_smoothness_mask_var * viz_rigidity_penalty_var), \n",
    "                                      \"norm\": self.def_norm_img},\n",
    "            }\n",
    "\n",
    "            self.vect_dict = {\n",
    "                'Predicted Residual': get_np(viz_pred_res_var),\n",
    "                'Source Residual': get_np(src_res_var),\n",
    "                'Inverted Residual': get_np(viz_inv_res),\n",
    "                'Combined': get_np(combined_identity_var)\n",
    "            }\n",
    "            \n",
    "            self.hist_dict = {\n",
    "                'Residual Histogram': get_np(viz_pred_res_var),\n",
    "            }\n",
    "            \n",
    "            if self.sup:\n",
    "                self.vect_dict['True Residual'] = get_np(viz_true_res_var),\n",
    "                self.vect_dict['Residual Error'] =  get_np(viz_true_res_var - viz_pred_res_var)\n",
    "    \n",
    "    def clean_up(self):\n",
    "        self.img_dict = {}\n",
    "        self.vect_dict = {}\n",
    "       \n",
    "    def loadimg(self, val, sup, section_count, img_id, x_section, y_section, choice, state_file):\n",
    "        self.update_state(img_id, sup, val, state_file)\n",
    "        \n",
    "        if choice in self.img_dict:\n",
    "            normalize = ('norm' in self.img_dict[choice]) and (self.img_dict[choice]['norm'])\n",
    "            is_mask = ('Mask ' in choice) or (' Mask' in choice)\n",
    "            is_seg = ('segment' in choice.lower())\n",
    "            img = copy.copy(prepare_for_show(self.img_dict[choice]['img']))\n",
    "            \n",
    "            x_section_size = img.shape[0] // section_count\n",
    "            y_section_size = img.shape[1] // section_count\n",
    "            \n",
    "            x_coords = (x_section_size * x_section, x_section_size * (x_section + 1))\n",
    "            y_coords = (y_section_size * y_section, y_section_size * (y_section + 1))\n",
    "\n",
    "            if choice in ['Diff',  'Masked Diff']:\n",
    "                print ('MSE: {}'.format(np.mean(np.abs(img[x_coords[0]:x_coords[1], y_coords[0]:y_coords[1]]))))\n",
    "            display_image(img, mask=is_mask, segmentation=is_seg, normalize=normalize, x_coords=x_coords, y_coords=y_coords)\n",
    "            \n",
    "        elif choice in self.vect_dict:\n",
    "            vecs = prepare_for_show(self.vect_dict[choice])\n",
    "\n",
    "            x_section_size = vecs.shape[0] // section_count\n",
    "            y_section_size = vecs.shape[1] // section_count\n",
    "            \n",
    "            x_coords = (x_section_size * x_section, x_section_size * (x_section + 1))\n",
    "            y_coords = (y_section_size * y_section, y_section_size * (y_section + 1))\n",
    "            \n",
    "            \n",
    "            visualize_residuals(vecs, x_coords=x_coords, y_coords=y_coords)\n",
    "\n",
    "        elif choice in self.hist_dict:\n",
    "            img = self.hist_dict[choice]\n",
    "            x_section_size = img.shape[0] // section_count\n",
    "            y_section_size = img.shape[1] // section_count\n",
    "            \n",
    "            x_coords = (x_section_size * x_section, x_section_size * (x_section + 1))\n",
    "            y_coords = (y_section_size * y_section, y_section_size * (y_section + 1))\n",
    "            visualize_histogram(img, x_coords=x_coords, y_coords=y_coords)\n",
    "       \n",
    "    def visualize(self, section_count=1, state_file=None, default_slice=9, default_x=0, default_y=0):\n",
    "        \n",
    "        self.id_selector = widgets.IntText(\n",
    "            value=default_slice,\n",
    "            description='Sample ID:',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        self.val_selector = widgets.Checkbox(\n",
    "            value=False,\n",
    "            description='Take from validation set',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.sup_selector = widgets.Checkbox(\n",
    "            value=self.def_sup,\n",
    "            description='Take from supervised dataset',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        self.section_count_selector = widgets.IntText(\n",
    "            value=section_count,\n",
    "            description='Section Count:',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        self.x_section_selector = widgets.IntText(\n",
    "            value=default_x,\n",
    "            description='X section:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.y_section_selector = widgets.IntText(\n",
    "            value=default_y,\n",
    "            description='Y section:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        buttons = ['Source', 'Warped Source', 'Target', 'Predicted Target', \n",
    "                   'Source Residual', 'Predicted Residual', 'Inverted Residual', \n",
    "                   'Combined',  'Diff', 'MSE Mask', 'Masked Diff', 'Residual Histogram',\n",
    "                   'Smoothness Mask', 'Smoothness', 'Rigidity', 'Masked Smoothness', 'Masked Rigidity']\n",
    "\n",
    "        # for supervised\n",
    "        #buttons += ['True Residual', 'Error histogram', 'Vector histogram', 'Residual Error'],\n",
    "        self.button_choice_1 = widgets.ToggleButtons(\n",
    "            options=buttons,\n",
    "            description='Image:',\n",
    "            disabled=False,\n",
    "            button_style='',\n",
    "        )\n",
    "        interact(self.loadimg, img_id=self.id_selector, val=self.val_selector, sup=self.sup_selector, \n",
    "                 section_count=self.section_count_selector, x_section=self.x_section_selector, y_section=self.y_section_selector, \n",
    "                 choice=self.button_choice_1, state_file=fixed(state_file))\n",
    "\n",
    "\n",
    "            \n",
    "class simple_visualizer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def display_multiimg(self, choice):\n",
    "        i = self.names.index(choice)\n",
    "        if isinstance(self.images[i], torch.Tensor):\n",
    "            self.images[i] = self.images[i].cpu().detach().numpy()\n",
    "        self.images[i].squeeze()\n",
    "        \n",
    "        plt.figure(figsize = (12,12))\n",
    "        if self.crop == 0:\n",
    "            plt.imshow(self.images[i], cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(self.images[i][self.crop:-self.crop, self.crop:-self.crop], cmap='gray')\n",
    "    \n",
    "    def loadimg(self, choice, section_count, x_section, y_section):\n",
    "        i = self.names.index(choice)\n",
    "        if isinstance(self.images[i], torch.Tensor):\n",
    "            self.images[i] = self.images[i].cpu().detach().numpy()\n",
    "        self.images[i].squeeze()\n",
    "        img = self.images[i].squeeze()\n",
    "        img = prepare_for_show(img)\n",
    "        x_section_size = img.shape[0] // section_count\n",
    "        y_section_size = img.shape[1] // section_count\n",
    "\n",
    "        x_coords = (x_section_size * x_section, x_section_size * (x_section + 1))\n",
    "        y_coords = (y_section_size * y_section, y_section_size * (y_section + 1))\n",
    "        \n",
    "        display_image(img, normalize=True, x_coords=x_coords, y_coords=y_coords)\n",
    "        \n",
    "    def visualize(self, images, names=None, crop=0, section_count=1, x_section=0, y_section=0):\n",
    "        if names is None:\n",
    "            names = range(len(images))\n",
    "        self.names = names\n",
    "        self.images = images\n",
    "        self.crop = crop\n",
    "        \n",
    "        button_choice = widgets.ToggleButtons(\n",
    "                options=names,\n",
    "                description='Image:',\n",
    "                disabled=False,\n",
    "                button_style='',\n",
    "            )\n",
    "        \n",
    "        self.section_count_selector = widgets.IntText(\n",
    "            value=section_count,\n",
    "            description='Section Count:',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        self.x_section_selector = widgets.IntText(\n",
    "            value=x_section,\n",
    "            description='X section:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.y_section_selector = widgets.IntText(\n",
    "            value=y_section,\n",
    "            description='Y section:',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        interact(self.loadimg, choice=button_choice, \n",
    "                 section_count=self.section_count_selector, \n",
    "                 x_section=self.x_section_selector, y_section=self.y_section_selector)\n",
    "\n",
    "\n",
    "def get_datasets():\n",
    "    dataset_mip = 4\n",
    "    stage = 2\n",
    "    checkpoint_name = 'metric_net'\n",
    "    \n",
    "    big_data = dataset.MultimipDataset(\"/usr/people/popovych/metro_datasets/large_test_x1\", field_tag=checkpoint_name)\n",
    "    train_dataset = big_data.get_train_dset(mip=dataset_mip, stage=stage, crop_mode='middle', cropped_size=1024)\n",
    "    return dataset_mip, train_dataset\n",
    "    \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "\n",
    "MAX_SEG_PER_CHUNK = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import artificery\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "def load_my_state_dict(model, state_dict):\n",
    "    own_state = model.state_dict()\n",
    "    for name, param in state_dict.items():\n",
    "        if name not in own_state:\n",
    "             continue\n",
    "        if isinstance(param, Parameter):\n",
    "            # backwards compatibility for serialized parameters\n",
    "            param = param.data\n",
    "        own_state[name].copy_(param)\n",
    "            \n",
    "def create_model(name, checkpoint_folder, checkpoint_init=False):                                                                                                                                                     \n",
    "    a = artificery.Artificery(checkpoint_init=checkpoint_init)    \n",
    "    \n",
    "    spec_path = os.path.join(checkpoint_folder, \"model_spec.json\")\n",
    "    my_p = a.parse(spec_path)                                                                                                                                                                \n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_folder, \"{}.state.pth.tar\".format(name))                                                                                                                     \n",
    "    if os.path.isfile(checkpoint_path):         \n",
    "        load_my_state_dict(my_p, torch.load(checkpoint_path))\n",
    "        #my_p.load_state_dict(torch.load(checkpoint_path))                                                                                                                                                  \n",
    "    my_p.name = name                                                                                                                                                                                       \n",
    "    return my_p.cuda()  \n",
    "\n",
    "def lap2(field):\n",
    "    def dxf(f):\n",
    "        p = Variable(torch.zeros((1,1,f.size(1),2))).cuda()\n",
    "        return torch.cat((p, f[:,1:-1,:,:] - f[:,2:,:,:], p), 1)\n",
    "    def dyf(f):\n",
    "        p = Variable(torch.zeros((1,f.size(1),1,2))).cuda()\n",
    "        return torch.cat((p, f[:,:,1:-1,:] - f[:,:,2:,:], p), 2)\n",
    "    result = [field_dx(field), field_dy(field), dxf(field), dyf(field)]\n",
    "    result = (sum(result) / 4.0) ** 2\n",
    "    result = sum(torch.sum(result, -1))\n",
    "    return result\n",
    "\n",
    "def field_dx(f, forward=False):\n",
    "    if forward:\n",
    "        delta = f[:,1:-1,:,:] - f[:,2:,:,:]\n",
    "    else:\n",
    "        delta = f[:,1:-1,:,:] - f[:,:-2,:,:]\n",
    "    result = delta\n",
    "    result = torch.nn.functional.pad(delta, pad=(0, 0, 0, 0, 1, 1, 0, 0))\n",
    "    return result\n",
    "\n",
    "def field_dy(f, forward=False):\n",
    "    if forward:\n",
    "        delta = f[:,:,1:-1,:] - f[:,:,2:,:]\n",
    "    else:\n",
    "        delta = f[:,:,1:-1,:] - f[:,:,:-2,:]\n",
    "    result = delta\n",
    "    result = torch.nn.functional.pad(delta, pad=(0, 0, 1, 1, 0, 0, 0, 0))\n",
    "    return result\n",
    "\n",
    "def field_dxy(f, forward=False):\n",
    "    if forward:\n",
    "        delta = f[:,1:-1,1:-1,:] - f[:,2:,2:,:]\n",
    "    else:\n",
    "        delta = f[:,1:-1,1:-1,:] - f[:,:-2,:-2,:]\n",
    "        \n",
    "    result = delta\n",
    "    result = torch.nn.functional.pad(delta, pad=(0, 0, 1, 1, 1, 1, 0, 0))\n",
    "    return result\n",
    "\n",
    "\n",
    "def pix_identity(size, batch=1, device='cuda'):\n",
    "    result = torch.zeros((batch, size, size, 2), device=device)\n",
    "    x = torch.arange(size, device=device)\n",
    "    result[:, :, :, 1] = x\n",
    "    result = torch.transpose(result, 1, 2)\n",
    "    result[:, :, :, 0] = x\n",
    "    result = torch.transpose(result, 1, 2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/people/popovych/metro_models/pyramid_m4m6m9/2_mip4in_mip4module/model/model_spec.json\n",
      "block_6convs_fms8to32_skip25.json\n",
      "categorical/categorical_compch15_gridfalse_maxvalue7_outch2_stepnull_trainsttrue.json\n",
      "block_6convs_fms8to32_skip25.json\n",
      "categorical/categorical_compch15_gridfalse_maxvalue7_outch2_stepnull_trainsttrue.json\n",
      "identity.json\n",
      "embedder_m0_3x3_fms3x.json\n",
      "block_5convs_3x3_fms1to3_skip14.json\n",
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "upsample_residuals.json\n",
      "identity.json\n",
      "Adding 'x147456_y147456_z17500' dataset.\n",
      "Loading file '/usr/people/popovych/metro_datasets/large_test_x1/x147456_y147456_z17500_MIP4.h5...'\n",
      "Loading file '/usr/people/popovych/metro_datasets/large_test_x1/x147456_y147456_z17500_MIP5.h5...'\n",
      "Loading file '/usr/people/popovych/metro_datasets/large_test_x1/x147456_y147456_z17500_MIP6.h5...'\n",
      "Loading file '/usr/people/popovych/metro_datasets/large_test_x1/x147456_y147456_z17500_MIP7.h5...'\n",
      "Loading file '/usr/people/popovych/metro_datasets/large_test_x1/field_1_x147456_y147456_z17500_MIP5_metric_net.h5...'\n",
      "Loading file '/usr/people/popovych/metro_datasets/large_test_x1/field_0_x147456_y147456_z17500_MIP4_metric_net.h5...'\n",
      "Loading file '/usr/people/popovych/metro_datasets/large_test_x1/field_0_x147456_y147456_z17500_MIP5_metric_net.h5...'\n",
      "Loading file '/usr/people/popovych/metro_datasets/large_test_x1/field_1_x147456_y147456_z17500_MIP4_metric_net.h5...'\n",
      "Loading file '/usr/people/popovych/metro_datasets/large_test_x1/field_0_x147456_y147456_z17500_MIP7_metric_net.h5...'\n",
      "Loading file '/usr/people/popovych/metro_datasets/large_test_x1/field_0_x147456_y147456_z17500_MIP6_metric_net.h5...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/people/popovych/artificery/artificery/parsers/categorical_regression/parse.py:38: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  requires_grad=False) - self.component_channels//2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a857a682401c437e8952dd0a9e44d760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=False, description='Take from validation set'), Checkbox(value=True, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpiont = \"metric_net\"\n",
    "#checkpiont = \"rigid_net\"\n",
    "#checkpiont = \"mse_standard\"\n",
    "#checkpoint_folder = \"/usr/people/popovych/metro_models/pyramid_m4m6m9/0_mip7in_mip9module/model\" #\"/usr/people/popovych/aligner/experiments/{}\".format(pyramid_name)\n",
    "\n",
    "#checkpoint_folder = \"/usr/people/popovych/metro_models/pyramid_m4m6m9/1_mip5in_mip6module/model\" #\"/usr/people/popovych/aligner/experiments/{}\".format(pyramid_name)\n",
    "\n",
    "checkpoint_folder = \"/usr/people/popovych/metro_models/pyramid_m4m6m9/2_mip4in_mip4module/model\" #\"/usr/people/popovych/aligner/experiments/{}\".format(pyramid_name)\n",
    "#checkpoint_folder = \"/usr/people/popovych/metro_models/pyramid_m5m9/1_mip4in_mip5module/model\" #\"/usr/people/popovych/aligner/experiments/{}\".format(pyramid_name)\n",
    "\n",
    "test_pyramid = aligner.Aligner(checkpoint_folder, checkpoint_name=checkpiont, train=False, \n",
    "                               finetune_lr=1e-1, finetune_sm=1200e0, finetune_iter=150, finetune=True)\n",
    "viz1 = PyramidVisualizer(test_pyramid)\n",
    "run_mip = 0\n",
    "\n",
    "viz1.def_norm_img = True\n",
    "viz1.set_model(test_pyramid)\n",
    "viz1.visualize(section_count=3, default_slice=24, default_x=1, default_y=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db0c04478f34f04ae2afd4d94b7133b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m0_out = test_pyramid.net.state['up']['0']['output']\n",
    "pred_res_start = torch.cuda.FloatTensor(viz1.vect_dict['Predicted Residual']).unsqueeze(0)\n",
    "m0_out_w = pred_res_start.field().from_pixels()(m0_out)\n",
    "\n",
    "v = [m0_out[0, 0], m0_out[0, 1], m0_out[0, 2], m0_out[0, 3], m0_out[0, 0],\n",
    "    m0_out[0, 4], m0_out[0, 5], m0_out[0, 6], m0_out[0, 7], m0_out[0, 4],\n",
    "    m0_out_w[0, 0], m0_out_w[0, 1], m0_out_w[0, 2], m0_out_w[0, 3], m0_out_w[0, 0],]\n",
    "simple_visualizer().visualize(v, section_count=3, x_section=1, y_section=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Aligner' object has no attribute 'state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cec341de2c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm7_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pyramid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'up'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mm7_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pyramid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'up'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mm8_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pyramid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'up'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mm8_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pyramid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'up'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mm9_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pyramid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'up'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/corgie/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 594\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Aligner' object has no attribute 'state'"
     ]
    }
   ],
   "source": [
    "m7_in = test_pyramid.state['up']['0']['input']\n",
    "m7_out = test_pyramid.state['up']['0']['output']\n",
    "m8_in = test_pyramid.state['up']['1']['input']\n",
    "m8_out = test_pyramid.state['up']['1']['output']\n",
    "m9_in = test_pyramid.state['up']['2']['input']\n",
    "m9_out = test_pyramid.state['up']['2']['output']\n",
    "v = [m7_out[0, 0], m8_out[0, 0],  m9_out[0, 0], m8_out[0, 0], m8_out[0, 1],\n",
    "     m7_out[0, 1], m8_out[0, 1],  m9_out[0, 1], m8_out[0, 0], m8_out[0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38343de74a564e0eaa90ce55b88219c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), value=0), In…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "simple_visualizer().visualize(v, section_count=3, x_section=1, y_section=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(44.5953, device='cuda:0')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz1.viz_sample['src_field'].abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import augment\n",
    "bundle = copy.deepcopy(viz1.run_sample)\n",
    "\n",
    "mse_mask, _ = get_mse_and_smoothness_masks(bundle, mse_keys_to_apply=viz1.mse_keys_to_apply, sm_keys_to_apply={})\n",
    "bundle['src'] = m7_out[0, :4].clone().unsqueeze(0)\n",
    "bundle['tgt'] = m7_out[0, 4:].clone().unsqueeze(0)\n",
    "bundle['pred_tgt'] = res_warp_img(bundle['src'], bundle['pred_res'])\n",
    "#bundle_norm = augment.normalize_bundle(bundle, per_feature_var=True, mask_fill=0, mask_defects=False, coarsen_mask_count=2)\n",
    "\n",
    "#(bundle_norm['src'][0, 3] != m7_out[0, 3]).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6072bb2750594520b584064f16e09298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = [bundle['src'][0, 0], bundle['src'][0, 1], bundle['src'][0, 2], bundle['src'][0, 3], bundle['pred_res'],\n",
    "     bundle['tgt'][0, 0], bundle['tgt'][0, 1], bundle['tgt'][0, 2], bundle['tgt'][0, 3], bundle['pred_res'],\n",
    "     bundle['pred_tgt'][0, 0], bundle['pred_tgt'][0, 1], bundle['pred_tgt'][0, 2], bundle['pred_tgt'][0, 3], bundle['pred_res'],\n",
    "     m7_out[0, 0], m7_out[0, 0],  m7_out[0, 1], m7_out[0, 2], m7_out[0, 3]]\n",
    "simple_visualizer().visualize(v, section_count=6, x_section=3, y_section=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1024, 1024])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundle['src'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v = [m7_out[0, 0], m7_out[0, 0],  m7_out[0, 1], m7_out[0, 2], m7_out[0, 3],  \n",
    "     m7_out[0, 4], m7_out[0, 4],  m7_out[0, 5], m7_out[0, 6], m7_out[0, 7],\n",
    "     m8_out[0, 0], m8_out[0, 0],  m8_out[0, 1], m8_out[0, 2], m8_out[0, 3],  \n",
    "     m8_out[0, 4], m8_out[0, 4], m8_out[0, 5], m8_out[0, 6], m8_out[0, 7],\n",
    "    m9_out[0, 0], m9_out[0, 0],  m9_out[0, 1], m9_out[0, 2], m9_out[0, 3],  \n",
    "     m9_out[0, 4], m9_out[0, 4], m9_out[0, 5], m9_out[0, 6], m9_out[0, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d29f11cf6b41768e647df8e61bc145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_visualizer().visualize(v, section_count=2, x_section=1, y_section=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b537b86bf9746deb236b7d368c2f45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_visualizer().visualize(v, section_count=2, x_section=0, y_section=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM: 191.48541259765625\n",
      "0.8348398 0.7312932 0.10354665\n",
      "New best: 85, No impr: 4, NaN: 0, Iter: 199\n",
      "0.68901265 0.6781345 0.010878172\n",
      "4.881175994873047\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "from metroem import finetuner\n",
    "from metroem import masks\n",
    "importlib.reload(finetuner)\n",
    "importlib.reload(masks)\n",
    "from metroem.finetuner import optimize_pre_post_ups\n",
    "\n",
    "src = m0_out[:, 1:4]#torch.cuda.FloatTensor(viz1.img_dict['Source']['img']).unsqueeze(0)\n",
    "tgt = m0_out[:, 5:]#torch.cuda.FloatTensor(viz1.img_dict['Target']['img']).unsqueeze(0)\n",
    "pred_res_start = torch.cuda.FloatTensor(viz1.vect_dict['Predicted Residual']).unsqueeze(0)\n",
    "src_defects = m0_out[0, 0] == 0\n",
    "tgt_defects = m0_out[0, 4] == 0\n",
    "\n",
    "def overfit_opt(src, tgt, pred_res_start, src_defects=None, tgt_defects=None, lr=18e-1):\n",
    "    \n",
    "    mse_keys_to_apply = {\n",
    "        'src': [\n",
    "            {'name': 'src_defects',\n",
    "             \"coarsen_ranges\": [ (1, 0)],\n",
    "             'binarization': {'strat': 'eq', 'value': 0},\n",
    "             }\n",
    "            ],\n",
    "        'tgt':[\n",
    "            {'name': 'tgt_defects',\n",
    "            'binarization': {'strat': 'eq', 'value': 0},\n",
    "             \"coarsen_ranges\": [ (1, 0)]\n",
    "             }\n",
    "        ]\n",
    "    }\n",
    "    sm_keys_to_apply = {                                                                                                 \n",
    "       \"src\": [                                                                                                                                                                                               \n",
    "         {\"name\": \"src_defects\",   \n",
    "            \"fm\": 0,\n",
    "            \"mask_value\": 1.0e-5,\n",
    "          'binarization': {'strat': 'eq', 'value': 0},\n",
    "             \"coarsen_ranges\": [ (1, 0)]\n",
    "         }                                                            \n",
    "       ],                                                                                                              \n",
    "       \"tgt\":[                                                                                                                                                                                            \n",
    "         {\"name\": \"tgt_defects\",                                                                                             \n",
    "            \"fm\": 0,    \n",
    "            \"mask_value\": 1.0e-5,\n",
    "          'binarization': {'strat': 'eq', 'value': 0},\n",
    "             \"coarsen_ranges\": [ (1, 0)]\n",
    "         }                                                                                          \n",
    "       ]                                                                                                              \n",
    "   }\n",
    "\n",
    "    src_small_defects = None\n",
    "    src_large_defects = None\n",
    "    \n",
    "        \n",
    "    if src_small_defects is not None:\n",
    "        src_small_defects = src_small_defects.squeeze(0)\n",
    "    else:\n",
    "        src_small_defects = torch.zeros_like(src)\n",
    "        \n",
    "    if src_large_defects is not None:\n",
    "        src_large_defects = src_large_defects.squeeze(0)\n",
    "    else:\n",
    "        src_large_defects = torch.zeros_like(src)\n",
    "    sm_f = 1.0\n",
    "    sm=1200/pred_res_start.abs().max() * sm_f\n",
    "    print (f\"SM: {sm}\")\n",
    "    pred_res_opt = optimize_pre_post_ups(src, tgt, pred_res_start,\n",
    "            src_defects=src_defects,\n",
    "            tgt_defects=tgt_defects,\n",
    "            crop=16, num_iter=200,\n",
    "            sm_keys_to_apply=sm_keys_to_apply,\n",
    "            mse_keys_to_apply=mse_keys_to_apply,\n",
    "            sm=sm, lr=lr)\n",
    "    return pred_res_opt\n",
    "\n",
    "pred_res_opt = overfit_opt(src, tgt, pred_res_start, src_defects=src_defects, tgt_defects=tgt_defects, lr=3e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137138aa77064213955b866a68f5dbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2, 3, 4, 5), value=0), IntText(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warped_src = torch.cuda.FloatTensor(viz1.img_dict['Warped Source']['img']).unsqueeze(0)\n",
    "src = torch.cuda.FloatTensor(viz1.img_dict['Source']['img']).unsqueeze(0)\n",
    "\n",
    "tgt = torch.cuda.FloatTensor(viz1.img_dict['Target']['img']).unsqueeze(0)\n",
    "\n",
    "pred_tgt_start = pred_res_start.field().from_pixels()(src)\n",
    "pred_tgt_opt = pred_res_opt.field().from_pixels()(src)\n",
    "\n",
    "trans_field = torch.zeros_like(pred_res_start, device=pred_res_start.device).field()\n",
    "trans_field.x = pred_res_start.field().x.mean()\n",
    "trans_field.y = pred_res_start.field().y.mean()\n",
    "src_trans = trans_field.from_pixels()(src)\n",
    "simple_visualizer().visualize([src, warped_src, tgt, pred_tgt_start, pred_tgt_opt, src_trans], \n",
    "                              section_count=5, x_section=1, y_section=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c9bb8b2c824c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m }\n\u001b[1;32m     57\u001b[0m opter = modelhouse.uncached_load_model_str('/usr/people/popovych/modelhouse/examples/models/finetune_field', \n\u001b[0;32m---> 58\u001b[0;31m                               \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                               )\n",
      "\u001b[0;32m~/modelhouse/modelhouse/loading/loading.py\u001b[0m in \u001b[0;36muncached_load_model_str\u001b[0;34m(path, params)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muncached_load_model_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0muncached_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/modelhouse/modelhouse/loading/loading.py\u001b[0m in \u001b[0;36muncached_load_model\u001b[0;34m(path, **params)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mput_files_and_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles_and_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mcreator_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"create.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mcreator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"create\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreator_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/modelhouse/modelhouse/loading/loading.py\u001b[0m in \u001b[0;36mimport_file\u001b[0;34m(module_name, file_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_cwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/.modelhouse/tmp_files/tmp0i88mv4f/create.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchfields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfinetune_loss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munsupervised_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.modelhouse/tmp_files/tmp0i88mv4f/finetune_loss.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpdb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_trace\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfinetune_masks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_mse_and_smoothness_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.modelhouse/tmp_files/tmp0i88mv4f/finetune_masks.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_np\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvolve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helpers'"
     ]
    }
   ],
   "source": [
    "import modelhouse\n",
    "import importlib\n",
    "import json\n",
    "importlib.reload(modelhouse)\n",
    "importlib.reload(masks)\n",
    "\n",
    "mse_keys_to_apply = {\n",
    "    'src': [\n",
    "        {'name': 'src_defects',\n",
    "         'binarization': {'strat': 'eq', 'value': 0},\n",
    "         \"coarsen_ranges\": [ (1, 0), (5, 25)] },\n",
    "        {'name': 'src',\n",
    "         \"coarsen_ranges\": [(1, 0)],\n",
    "         'fm': 0,\n",
    "         'binarization': {'strat': 'neq', 'value': 0}\n",
    "         }\n",
    "        ],\n",
    "    'tgt':[\n",
    "        {'name': 'tgt_defects',\n",
    "         'binarization': {'strat': 'eq', 'value': 0},\n",
    "         \"coarsen_ranges\": [(3, 0)]},\n",
    "        {'name': 'tgt',\n",
    "         'fm': 0, \n",
    "         \"coarsen_ranges\": [(3, 0)],\n",
    "         'binarization': {'strat': 'neq', 'value': 0}\n",
    "         }\n",
    "    ]\n",
    "}\n",
    "sm_keys_to_apply = {                                                                                                 \n",
    "   \"src\": [                                                                                                          \n",
    "       {\"name\": \"src_defects\",                                                                                      \n",
    "        \"binarization\": {\"strat\": \"eq\", \"value\": 0},                                                               \n",
    "        \"not_coarsen_ranges\": [[0, 0], [4, 5], [0, 0.2]],                                                             \n",
    "        \"mask_value\": 1.0e-9},                                                                                       \n",
    "     {\"name\": \"src\",                                                                                             \n",
    "        \"fm\": 0,       \n",
    "        \"binarization\": {\"strat\": \"neq\", \"value\": 0}}                                                            \n",
    "   ],                                                                                                              \n",
    "   \"tgt\":[                                                                                                        \n",
    "       {\"name\": \"tgt_defects\",                                                                                   \n",
    "        \"binarization\": {\"strat\": \"eq\", \"value\": 0},                                                                 \n",
    "        #\"coarsen_ranges\": [[2, 0], [8, 0.2], [2, 0.4], [3, 0.6], [4, 0.8]],                                                              \n",
    "        \"mask_value\": 0.0e-5}                                                                                         \n",
    "   ]                                                                                                              \n",
    "}\n",
    "\n",
    "    \n",
    "model_params = {\n",
    "    \"num_iter\": 100, \n",
    "    \"lr\": 5e-2, \n",
    "    \"sm\": 3e1, \n",
    "    \"downs_count\": 0, \n",
    "    \"crop\": 16,\n",
    "    \"sm_keys_to_apply\": sm_keys_to_apply, \n",
    "    \"mse_keys_to_apply\": mse_keys_to_apply\n",
    "}\n",
    "opter = modelhouse.uncached_load_model_str('/usr/people/popovych/modelhouse/examples/models/finetune_field', \n",
    "                              json.dumps(model_params)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opter_res = opter(src, tgt, pred_res_start, src_defects=src_defects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.cuda.FloatTensor(viz1.img_dict['Source']['img']).unsqueeze(0)\n",
    "tgt = torch.cuda.FloatTensor(viz1.img_dict['Target']['img']).unsqueeze(0)\n",
    "pred_tgt_start = res_warp_img(src, pred_res_start, is_pix_res=True)\n",
    "pred_tgt_opt = opter_res.from_pixels()(src)\n",
    "simple_visualizer().visualize([src, src_defects, tgt, pred_tgt_start, pred_tgt_opt], \n",
    "                              section_count=6, x_section=1, y_section=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0566, device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0578, device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corgie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
